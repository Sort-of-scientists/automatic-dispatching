{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a60077-2b1e-4dd6-aee5-3aba869511e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/11/10 01:10:05 INFO mlflow.tracking.fluent: Experiment with name '–¢–∏–ø_–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è_data_v2.0_expanded_data' does not exist. Creating a new experiment.\n",
      "2024-11-10 01:10:05,587 Reading data from datav2\n",
      "2024-11-10 01:10:05,587 Train: datav2/train.csv\n",
      "2024-11-10 01:10:05,587 Dev: datav2/dev.csv\n",
      "2024-11-10 01:10:05,587 Test: datav2/test.csv\n",
      "2024-11-10 01:10:05,632 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1770.96it/s]\n",
      "2024-11-10 01:10:11,204 Dictionary created for label 'label' with 3 values: –ù–æ—É—Ç–±—É–∫ (seen 8130 times), –°–µ—Ä–≤–µ—Ä (seen 1075 times), –°–•–î (seen 655 times)\n",
      "2024-11-10 01:10:13,600 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(46167, 1024, padding_idx=1)\n",
      "        (position_embeddings): Embedding(8194, 1024, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 01:10:13,602 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 01:10:13,602 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Train:  9860 sentences\n",
      "2024-11-10 01:10:13,602         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 01:10:13,602 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Training Params:\n",
      "2024-11-10 01:10:13,602  - learning_rate: \"5e-05\" \n",
      "2024-11-10 01:10:13,602  - mini_batch_size: \"8\"\n",
      "2024-11-10 01:10:13,602  - max_epochs: \"5\"\n",
      "2024-11-10 01:10:13,602  - shuffle: \"True\"\n",
      "2024-11-10 01:10:13,602 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Plugins:\n",
      "2024-11-10 01:10:13,602  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,603 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 01:10:13,603  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,603 Computation:\n",
      "2024-11-10 01:10:13,603  - compute on device: cuda:0\n",
      "2024-11-10 01:10:13,603  - embedding storage: none\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,603 Model training base path: \"modelsv2/datav2/deepvk_USER_bge_m3\"\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:30,475 epoch 1 - iter 123/1233 - loss 0.30254450 - time (sec): 16.87 - samples/sec: 58.32 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:10:47,358 epoch 1 - iter 246/1233 - loss 0.16418342 - time (sec): 33.75 - samples/sec: 58.31 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:11:04,482 epoch 1 - iter 369/1233 - loss 0.12309941 - time (sec): 50.88 - samples/sec: 58.02 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:11:21,394 epoch 1 - iter 492/1233 - loss 0.09244829 - time (sec): 67.79 - samples/sec: 58.06 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:11:38,604 epoch 1 - iter 615/1233 - loss 0.08023119 - time (sec): 85.00 - samples/sec: 57.88 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 01:11:55,532 epoch 1 - iter 738/1233 - loss 0.07664285 - time (sec): 101.93 - samples/sec: 57.92 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 01:12:12,653 epoch 1 - iter 861/1233 - loss 0.06917857 - time (sec): 119.05 - samples/sec: 57.86 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 01:12:29,759 epoch 1 - iter 984/1233 - loss 0.06328982 - time (sec): 136.15 - samples/sec: 57.82 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 01:12:46,858 epoch 1 - iter 1107/1233 - loss 0.05626861 - time (sec): 153.25 - samples/sec: 57.79 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 01:13:03,808 epoch 1 - iter 1230/1233 - loss 0.05340093 - time (sec): 170.20 - samples/sec: 57.81 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 01:13:04,217 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:13:04,217 EPOCH 1 done: loss 0.0533 - lr: 0.000044\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:13:15,749 DEV : loss 0.28919607400894165 - f1-score (micro avg)  0.9845\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:13:27,641 TEST : loss 0.28919607400894165 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 01:13:27,834 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:13:44,556 epoch 2 - iter 123/1233 - loss 0.00825536 - time (sec): 16.72 - samples/sec: 58.85 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 01:14:01,707 epoch 2 - iter 246/1233 - loss 0.01371782 - time (sec): 33.87 - samples/sec: 58.10 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 01:14:18,726 epoch 2 - iter 369/1233 - loss 0.02144445 - time (sec): 50.89 - samples/sec: 58.01 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 01:14:35,931 epoch 2 - iter 492/1233 - loss 0.02544656 - time (sec): 68.09 - samples/sec: 57.80 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:14:52,727 epoch 2 - iter 615/1233 - loss 0.03741904 - time (sec): 84.89 - samples/sec: 57.96 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 01:15:09,770 epoch 2 - iter 738/1233 - loss 0.18434652 - time (sec): 101.93 - samples/sec: 57.92 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 01:15:26,668 epoch 2 - iter 861/1233 - loss 0.25613014 - time (sec): 118.83 - samples/sec: 57.96 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 01:15:43,507 epoch 2 - iter 984/1233 - loss 0.31246242 - time (sec): 135.67 - samples/sec: 58.02 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 01:16:00,554 epoch 2 - iter 1107/1233 - loss 0.34549953 - time (sec): 152.72 - samples/sec: 57.99 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 01:16:17,701 epoch 2 - iter 1230/1233 - loss 0.37497546 - time (sec): 169.86 - samples/sec: 57.93 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 01:16:18,115 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:16:18,115 EPOCH 2 done: loss 0.3755 - lr: 0.000033\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.12it/s]\n",
      "2024-11-10 01:16:29,787 DEV : loss 0.6520723104476929 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:16:41,462 TEST : loss 0.6520723104476929 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:16:41,654 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:16:58,678 epoch 3 - iter 123/1233 - loss 0.62773801 - time (sec): 17.02 - samples/sec: 57.80 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 01:17:15,760 epoch 3 - iter 246/1233 - loss 0.62210512 - time (sec): 34.10 - samples/sec: 57.71 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 01:17:33,004 epoch 3 - iter 369/1233 - loss 0.61318264 - time (sec): 51.35 - samples/sec: 57.49 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:17:50,105 epoch 3 - iter 492/1233 - loss 0.60941451 - time (sec): 68.45 - samples/sec: 57.50 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 01:18:07,211 epoch 3 - iter 615/1233 - loss 0.60524674 - time (sec): 85.56 - samples/sec: 57.51 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 01:18:24,332 epoch 3 - iter 738/1233 - loss 0.60758326 - time (sec): 102.68 - samples/sec: 57.50 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 01:18:41,672 epoch 3 - iter 861/1233 - loss 0.60624155 - time (sec): 120.02 - samples/sec: 57.39 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 01:18:58,792 epoch 3 - iter 984/1233 - loss 0.60779014 - time (sec): 137.14 - samples/sec: 57.40 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 01:19:15,755 epoch 3 - iter 1107/1233 - loss 0.61046526 - time (sec): 154.10 - samples/sec: 57.47 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 01:19:32,986 epoch 3 - iter 1230/1233 - loss 0.61286036 - time (sec): 171.33 - samples/sec: 57.43 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 01:19:33,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:19:33,391 EPOCH 3 done: loss 0.6131 - lr: 0.000022\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:19:44,895 DEV : loss 0.641645610332489 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.10it/s]\n",
      "2024-11-10 01:19:56,869 TEST : loss 0.641645610332489 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:19:57,089 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:20:14,136 epoch 4 - iter 123/1233 - loss 0.59894515 - time (sec): 17.04 - samples/sec: 57.73 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 01:20:31,304 epoch 4 - iter 246/1233 - loss 0.61325126 - time (sec): 34.21 - samples/sec: 57.52 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:20:48,334 epoch 4 - iter 369/1233 - loss 0.60893877 - time (sec): 51.24 - samples/sec: 57.61 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 01:21:05,362 epoch 4 - iter 492/1233 - loss 0.60482420 - time (sec): 68.27 - samples/sec: 57.65 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 01:21:22,399 epoch 4 - iter 615/1233 - loss 0.59883779 - time (sec): 85.31 - samples/sec: 57.67 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 01:21:39,321 epoch 4 - iter 738/1233 - loss 0.59955653 - time (sec): 102.23 - samples/sec: 57.75 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 01:21:56,538 epoch 4 - iter 861/1233 - loss 0.59304641 - time (sec): 119.45 - samples/sec: 57.67 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 01:22:13,542 epoch 4 - iter 984/1233 - loss 0.59566032 - time (sec): 136.45 - samples/sec: 57.69 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 01:22:30,678 epoch 4 - iter 1107/1233 - loss 0.60190442 - time (sec): 153.59 - samples/sec: 57.66 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 01:22:47,766 epoch 4 - iter 1230/1233 - loss 0.60396732 - time (sec): 170.68 - samples/sec: 57.65 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 01:22:48,160 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:22:48,160 EPOCH 4 done: loss 0.6038 - lr: 0.000011\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:22:59,680 DEV : loss 0.632508397102356 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:23:11,636 TEST : loss 0.632508397102356 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:23:11,837 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:23:28,941 epoch 5 - iter 123/1233 - loss 0.62867308 - time (sec): 17.10 - samples/sec: 57.54 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:23:45,914 epoch 5 - iter 246/1233 - loss 0.62175294 - time (sec): 34.08 - samples/sec: 57.75 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 01:24:02,947 epoch 5 - iter 369/1233 - loss 0.59398581 - time (sec): 51.11 - samples/sec: 57.76 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 01:24:20,197 epoch 5 - iter 492/1233 - loss 0.58551403 - time (sec): 68.36 - samples/sec: 57.58 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 01:24:37,204 epoch 5 - iter 615/1233 - loss 0.58634525 - time (sec): 85.37 - samples/sec: 57.63 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 01:24:54,610 epoch 5 - iter 738/1233 - loss 0.59264108 - time (sec): 102.77 - samples/sec: 57.45 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 01:25:11,663 epoch 5 - iter 861/1233 - loss 0.59540056 - time (sec): 119.82 - samples/sec: 57.48 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 01:25:28,922 epoch 5 - iter 984/1233 - loss 0.59231490 - time (sec): 137.08 - samples/sec: 57.42 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 01:25:45,944 epoch 5 - iter 1107/1233 - loss 0.59249888 - time (sec): 154.11 - samples/sec: 57.47 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 01:26:02,986 epoch 5 - iter 1230/1233 - loss 0.59473729 - time (sec): 171.15 - samples/sec: 57.49 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 01:26:03,375 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:26:03,375 EPOCH 5 done: loss 0.5943 - lr: 0.000000\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:26:14,914 DEV : loss 0.6485000252723694 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:26:26,615 TEST : loss 0.6485000252723694 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:26:29,321 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:26:29,322 Testing using last state of model ...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:11<00:00,  1.14it/s]\n",
      "2024-11-10 01:26:40,774 \n",
      "Results:\n",
      "- F-score (micro) 0.7938\n",
      "- F-score (macro) 0.295\n",
      "- Accuracy 0.7938\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     –ù–æ—É—Ç–±—É–∫     0.7938    1.0000    0.8851       154\n",
      "      –°–µ—Ä–≤–µ—Ä     0.0000    0.0000    0.0000        29\n",
      "         –°–•–î     0.0000    0.0000    0.0000        11\n",
      "\n",
      "    accuracy                         0.7938       194\n",
      "   macro avg     0.2646    0.3333    0.2950       194\n",
      "weighted avg     0.6301    0.7938    0.7026       194\n",
      "\n",
      "2024-11-10 01:26:40,774 ----------------------------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:08<00:00,  2.92it/s]\n",
      "2024/11/10 01:27:03 INFO mlflow.tracking._tracking_service.client: üèÉ View run inquisitive-colt-478 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/00fab0584aa647a0a70d0b6093ae2a35.\n",
      "2024/11/10 01:27:03 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 01:27:10,090 Reading data from datav2\n",
      "2024-11-10 01:27:10,090 Train: datav2/train.csv\n",
      "2024-11-10 01:27:10,090 Dev: datav2/dev.csv\n",
      "2024-11-10 01:27:10,090 Test: datav2/test.csv\n",
      "2024-11-10 01:27:10,140 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1755.22it/s]\n",
      "2024-11-10 01:27:15,762 Dictionary created for label 'label' with 3 values: –ù–æ—É—Ç–±—É–∫ (seen 8130 times), –°–µ—Ä–≤–µ—Ä (seen 1075 times), –°–•–î (seen 655 times)\n",
      "2024-11-10 01:27:17,195 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): DebertaModel(\n",
      "      (embeddings): DebertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50266, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): DebertaLayerNorm()\n",
      "        (dropout): StableDropout()\n",
      "      )\n",
      "      (encoder): DebertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x DebertaLayer(\n",
      "            (attention): DebertaAttention(\n",
      "              (self): DisentangledSelfAttention(\n",
      "                (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "              (output): DebertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): DebertaLayerNorm()\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): DebertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): DebertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 01:27:17,196 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 01:27:17,196 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Train:  9860 sentences\n",
      "2024-11-10 01:27:17,196         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 01:27:17,196 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Training Params:\n",
      "2024-11-10 01:27:17,196  - learning_rate: \"5e-05\" \n",
      "2024-11-10 01:27:17,196  - mini_batch_size: \"8\"\n",
      "2024-11-10 01:27:17,196  - max_epochs: \"5\"\n",
      "2024-11-10 01:27:17,196  - shuffle: \"True\"\n",
      "2024-11-10 01:27:17,196 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Plugins:\n",
      "2024-11-10 01:27:17,196  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,197 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 01:27:17,197  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,197 Computation:\n",
      "2024-11-10 01:27:17,197  - compute on device: cuda:0\n",
      "2024-11-10 01:27:17,197  - embedding storage: none\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,197 Model training base path: \"modelsv2/datav2/deepvk_USER_base\"\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:25,486 epoch 1 - iter 123/1233 - loss 0.32389420 - time (sec): 8.29 - samples/sec: 118.72 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:27:33,589 epoch 1 - iter 246/1233 - loss 0.16524380 - time (sec): 16.39 - samples/sec: 120.06 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:27:41,887 epoch 1 - iter 369/1233 - loss 0.11871837 - time (sec): 24.69 - samples/sec: 119.57 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:27:49,648 epoch 1 - iter 492/1233 - loss 0.09643388 - time (sec): 32.45 - samples/sec: 121.29 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:27:58,212 epoch 1 - iter 615/1233 - loss 0.08686119 - time (sec): 41.01 - samples/sec: 119.96 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 01:28:06,951 epoch 1 - iter 738/1233 - loss 0.07384475 - time (sec): 49.75 - samples/sec: 118.66 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 01:28:15,360 epoch 1 - iter 861/1233 - loss 0.07284237 - time (sec): 58.16 - samples/sec: 118.43 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 01:28:23,792 epoch 1 - iter 984/1233 - loss 0.06490788 - time (sec): 66.59 - samples/sec: 118.21 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 01:28:32,346 epoch 1 - iter 1107/1233 - loss 0.05911213 - time (sec): 75.15 - samples/sec: 117.85 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 01:28:39,564 epoch 1 - iter 1230/1233 - loss 0.05609780 - time (sec): 82.37 - samples/sec: 119.47 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 01:28:39,754 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:28:39,755 EPOCH 1 done: loss 0.0560 - lr: 0.000044\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.12it/s]\n",
      "2024-11-10 01:28:41,193 DEV : loss 0.12663452327251434 - f1-score (micro avg)  0.9794\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.03it/s]\n",
      "2024-11-10 01:28:43,068 TEST : loss 0.12663452327251434 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 01:28:43,262 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:28:51,055 epoch 2 - iter 123/1233 - loss 0.00859892 - time (sec): 7.79 - samples/sec: 126.27 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 01:28:59,564 epoch 2 - iter 246/1233 - loss 0.01579806 - time (sec): 16.30 - samples/sec: 120.73 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 01:29:08,128 epoch 2 - iter 369/1233 - loss 0.01053553 - time (sec): 24.87 - samples/sec: 118.72 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 01:29:16,678 epoch 2 - iter 492/1233 - loss 0.01251504 - time (sec): 33.42 - samples/sec: 117.79 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:29:25,195 epoch 2 - iter 615/1233 - loss 0.01659385 - time (sec): 41.93 - samples/sec: 117.33 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 01:29:33,590 epoch 2 - iter 738/1233 - loss 0.02661105 - time (sec): 50.33 - samples/sec: 117.31 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 01:29:41,917 epoch 2 - iter 861/1233 - loss 0.02789911 - time (sec): 58.65 - samples/sec: 117.43 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 01:29:49,700 epoch 2 - iter 984/1233 - loss 0.06339075 - time (sec): 66.44 - samples/sec: 118.49 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 01:29:57,757 epoch 2 - iter 1107/1233 - loss 0.07533164 - time (sec): 74.49 - samples/sec: 118.88 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 01:30:05,384 epoch 2 - iter 1230/1233 - loss 0.08408192 - time (sec): 82.12 - samples/sec: 119.82 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 01:30:05,552 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:30:05,552 EPOCH 2 done: loss 0.0842 - lr: 0.000033\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.26it/s]\n",
      "2024-11-10 01:30:06,968 DEV : loss 0.2243126928806305 - f1-score (micro avg)  0.9227\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  8.09it/s]\n",
      "2024-11-10 01:30:08,780 TEST : loss 0.2243126928806305 - f1-score (micro avg)  0.9227\n",
      "2024-11-10 01:30:08,974 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:30:15,951 epoch 3 - iter 123/1233 - loss 0.17272154 - time (sec): 6.98 - samples/sec: 141.05 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 01:30:24,172 epoch 3 - iter 246/1233 - loss 0.14596833 - time (sec): 15.20 - samples/sec: 129.50 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 01:30:31,723 epoch 3 - iter 369/1233 - loss 0.13985149 - time (sec): 22.75 - samples/sec: 129.77 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:30:40,056 epoch 3 - iter 492/1233 - loss 0.13880050 - time (sec): 31.08 - samples/sec: 126.64 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 01:30:47,368 epoch 3 - iter 615/1233 - loss 0.14689119 - time (sec): 38.39 - samples/sec: 128.15 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 01:30:54,996 epoch 3 - iter 738/1233 - loss 0.17159819 - time (sec): 46.02 - samples/sec: 128.29 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 01:31:03,379 epoch 3 - iter 861/1233 - loss 0.23225603 - time (sec): 54.40 - samples/sec: 126.61 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 01:31:11,966 epoch 3 - iter 984/1233 - loss 0.27469699 - time (sec): 62.99 - samples/sec: 124.97 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 01:31:20,475 epoch 3 - iter 1107/1233 - loss 0.31025357 - time (sec): 71.50 - samples/sec: 123.86 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 01:31:29,064 epoch 3 - iter 1230/1233 - loss 0.34056892 - time (sec): 80.09 - samples/sec: 122.86 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 01:31:29,268 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:31:29,269 EPOCH 3 done: loss 0.3405 - lr: 0.000022\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  8.13it/s]\n",
      "2024-11-10 01:31:30,880 DEV : loss 0.6929484009742737 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.26it/s]\n",
      "2024-11-10 01:31:32,490 TEST : loss 0.6929484009742737 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:31:32,697 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:31:41,424 epoch 4 - iter 123/1233 - loss 0.59128179 - time (sec): 8.73 - samples/sec: 112.76 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 01:31:49,811 epoch 4 - iter 246/1233 - loss 0.59624698 - time (sec): 17.11 - samples/sec: 115.00 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:31:58,240 epoch 4 - iter 369/1233 - loss 0.57837341 - time (sec): 25.54 - samples/sec: 115.57 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 01:32:06,931 epoch 4 - iter 492/1233 - loss 0.56980733 - time (sec): 34.23 - samples/sec: 114.98 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 01:32:15,347 epoch 4 - iter 615/1233 - loss 0.56779731 - time (sec): 42.65 - samples/sec: 115.36 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 01:32:22,610 epoch 4 - iter 738/1233 - loss 0.57474952 - time (sec): 49.91 - samples/sec: 118.29 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 01:32:29,523 epoch 4 - iter 861/1233 - loss 0.56484829 - time (sec): 56.83 - samples/sec: 121.21 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 01:32:36,514 epoch 4 - iter 984/1233 - loss 0.54675074 - time (sec): 63.82 - samples/sec: 123.36 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 01:32:44,025 epoch 4 - iter 1107/1233 - loss 0.51637023 - time (sec): 71.33 - samples/sec: 124.16 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 01:32:51,547 epoch 4 - iter 1230/1233 - loss 0.48358855 - time (sec): 78.85 - samples/sec: 124.80 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 01:32:51,710 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:32:51,710 EPOCH 4 done: loss 0.4832 - lr: 0.000011\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.19it/s]\n",
      "2024-11-10 01:32:53,138 DEV : loss 0.3298746645450592 - f1-score (micro avg)  0.8711\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  7.90it/s]\n",
      "2024-11-10 01:32:54,988 TEST : loss 0.3298746645450592 - f1-score (micro avg)  0.8711\n",
      "2024-11-10 01:32:55,189 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:33:03,127 epoch 5 - iter 123/1233 - loss 0.17361408 - time (sec): 7.94 - samples/sec: 123.97 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:33:11,385 epoch 5 - iter 246/1233 - loss 0.17112680 - time (sec): 16.20 - samples/sec: 121.52 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 01:33:18,301 epoch 5 - iter 369/1233 - loss 0.18408901 - time (sec): 23.11 - samples/sec: 127.73 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 01:33:25,556 epoch 5 - iter 492/1233 - loss 0.18536852 - time (sec): 30.37 - samples/sec: 129.62 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 01:33:33,267 epoch 5 - iter 615/1233 - loss 0.18364063 - time (sec): 38.08 - samples/sec: 129.21 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 01:33:40,922 epoch 5 - iter 738/1233 - loss 0.17840393 - time (sec): 45.73 - samples/sec: 129.10 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 01:33:49,349 epoch 5 - iter 861/1233 - loss 0.17844636 - time (sec): 54.16 - samples/sec: 127.18 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 01:33:57,940 epoch 5 - iter 984/1233 - loss 0.17893981 - time (sec): 62.75 - samples/sec: 125.45 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 01:34:06,439 epoch 5 - iter 1107/1233 - loss 0.17640476 - time (sec): 71.25 - samples/sec: 124.30 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 01:34:14,686 epoch 5 - iter 1230/1233 - loss 0.17741990 - time (sec): 79.50 - samples/sec: 123.78 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 01:34:14,890 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:14,890 EPOCH 5 done: loss 0.1773 - lr: 0.000000\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  7.91it/s]\n",
      "2024-11-10 01:34:16,547 DEV : loss 0.36851274967193604 - f1-score (micro avg)  0.8711\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.17it/s]\n",
      "2024-11-10 01:34:18,171 TEST : loss 0.36851274967193604 - f1-score (micro avg)  0.8711\n",
      "2024-11-10 01:34:19,138 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:19,139 Testing using last state of model ...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  8.07it/s]\n",
      "2024-11-10 01:34:20,761 \n",
      "Results:\n",
      "- F-score (micro) 0.8711\n",
      "- F-score (macro) 0.5504\n",
      "- Accuracy 0.8711\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     –ù–æ—É—Ç–±—É–∫     1.0000    0.9091    0.9524       154\n",
      "      –°–µ—Ä–≤–µ—Ä     0.5370    1.0000    0.6988        29\n",
      "         –°–•–î     0.0000    0.0000    0.0000        11\n",
      "\n",
      "    accuracy                         0.8711       194\n",
      "   macro avg     0.5123    0.6364    0.5504       194\n",
      "weighted avg     0.8741    0.8711    0.8605       194\n",
      "\n",
      "2024-11-10 01:34:20,762 ----------------------------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 21.40it/s]\n",
      "2024/11/10 01:34:26 INFO mlflow.tracking._tracking_service.client: üèÉ View run dapper-sloth-973 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/bedb9a493d1d48ba9db7df74a1adbdc8.\n",
      "2024/11/10 01:34:26 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 01:34:32,886 Reading data from datav2\n",
      "2024-11-10 01:34:32,886 Train: datav2/train.csv\n",
      "2024-11-10 01:34:32,886 Dev: datav2/dev.csv\n",
      "2024-11-10 01:34:32,886 Test: datav2/test.csv\n",
      "2024-11-10 01:34:32,933 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1769.06it/s]\n",
      "2024-11-10 01:34:38,511 Dictionary created for label 'label' with 3 values: –ù–æ—É—Ç–±—É–∫ (seen 8130 times), –°–µ—Ä–≤–µ—Ä (seen 1075 times), –°–•–î (seen 655 times)\n",
      "2024-11-10 01:34:42,089 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(250003, 1024, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Train:  9860 sentences\n",
      "2024-11-10 01:34:42,091         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Training Params:\n",
      "2024-11-10 01:34:42,091  - learning_rate: \"5e-05\" \n",
      "2024-11-10 01:34:42,091  - mini_batch_size: \"8\"\n",
      "2024-11-10 01:34:42,091  - max_epochs: \"5\"\n",
      "2024-11-10 01:34:42,091  - shuffle: \"True\"\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Plugins:\n",
      "2024-11-10 01:34:42,091  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 01:34:42,091  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 01:34:42,092 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,092 Computation:\n",
      "2024-11-10 01:34:42,092  - compute on device: cuda:0\n",
      "2024-11-10 01:34:42,092  - embedding storage: none\n",
      "2024-11-10 01:34:42,092 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,092 Model training base path: \"modelsv2/datav2/intfloat_multilingual_e5_large_instruct\"\n",
      "2024-11-10 01:34:42,092 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,092 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:35:02,087 epoch 1 - iter 123/1233 - loss 0.28510497 - time (sec): 19.99 - samples/sec: 49.21 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:35:22,040 epoch 1 - iter 246/1233 - loss 0.15675579 - time (sec): 39.95 - samples/sec: 49.27 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:35:42,175 epoch 1 - iter 369/1233 - loss 0.10712950 - time (sec): 60.08 - samples/sec: 49.13 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:36:02,178 epoch 1 - iter 492/1233 - loss 0.09558776 - time (sec): 80.08 - samples/sec: 49.15 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:36:22,260 epoch 1 - iter 615/1233 - loss 0.08139954 - time (sec): 100.17 - samples/sec: 49.12 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 01:36:42,157 epoch 1 - iter 738/1233 - loss 0.07600239 - time (sec): 120.06 - samples/sec: 49.17 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 01:37:02,239 epoch 1 - iter 861/1233 - loss 0.09148924 - time (sec): 140.15 - samples/sec: 49.15 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 01:37:22,293 epoch 1 - iter 984/1233 - loss 0.08309864 - time (sec): 160.20 - samples/sec: 49.14 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 01:37:42,287 epoch 1 - iter 1107/1233 - loss 0.08057814 - time (sec): 180.19 - samples/sec: 49.15 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 01:38:02,245 epoch 1 - iter 1230/1233 - loss 0.08208214 - time (sec): 200.15 - samples/sec: 49.16 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 01:38:02,696 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:38:02,696 EPOCH 1 done: loss 0.0834 - lr: 0.000044\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.21it/s]\n",
      "2024-11-10 01:38:05,799 DEV : loss 1.3000657558441162 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.24it/s]\n",
      "2024-11-10 01:38:09,275 TEST : loss 1.3000657558441162 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:38:09,471 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:38:29,650 epoch 2 - iter 123/1233 - loss 0.75884688 - time (sec): 20.18 - samples/sec: 48.77 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 01:38:49,780 epoch 2 - iter 246/1233 - loss 0.70812750 - time (sec): 40.31 - samples/sec: 48.82 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 01:39:09,563 epoch 2 - iter 369/1233 - loss 0.69779509 - time (sec): 60.09 - samples/sec: 49.13 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 01:39:29,622 epoch 2 - iter 492/1233 - loss 0.67755514 - time (sec): 80.15 - samples/sec: 49.11 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:39:49,425 epoch 2 - iter 615/1233 - loss 0.66662362 - time (sec): 99.95 - samples/sec: 49.22 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 01:40:09,402 epoch 2 - iter 738/1233 - loss 0.65954769 - time (sec): 119.93 - samples/sec: 49.23 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 01:40:29,343 epoch 2 - iter 861/1233 - loss 0.65496456 - time (sec): 139.87 - samples/sec: 49.25 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 01:40:49,402 epoch 2 - iter 984/1233 - loss 0.64892974 - time (sec): 159.93 - samples/sec: 49.22 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 01:41:09,181 epoch 2 - iter 1107/1233 - loss 0.64029426 - time (sec): 179.71 - samples/sec: 49.28 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 01:41:28,961 epoch 2 - iter 1230/1233 - loss 0.63898031 - time (sec): 199.49 - samples/sec: 49.33 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 01:41:29,459 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:41:29,459 EPOCH 2 done: loss 0.6388 - lr: 0.000033\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.25it/s]\n",
      "2024-11-10 01:41:32,532 DEV : loss 0.6691238284111023 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.30it/s]\n",
      "2024-11-10 01:41:35,763 TEST : loss 0.6691238284111023 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:41:36,144 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:41:55,916 epoch 3 - iter 123/1233 - loss 0.66237909 - time (sec): 19.77 - samples/sec: 49.77 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 01:42:15,637 epoch 3 - iter 246/1233 - loss 0.62206798 - time (sec): 39.49 - samples/sec: 49.83 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 01:42:35,798 epoch 3 - iter 369/1233 - loss 0.62717145 - time (sec): 59.65 - samples/sec: 49.49 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:42:55,455 epoch 3 - iter 492/1233 - loss 0.61705122 - time (sec): 79.31 - samples/sec: 49.63 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 01:43:15,566 epoch 3 - iter 615/1233 - loss 0.61367134 - time (sec): 99.42 - samples/sec: 49.49 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 01:43:35,538 epoch 3 - iter 738/1233 - loss 0.61679914 - time (sec): 119.39 - samples/sec: 49.45 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 01:43:55,456 epoch 3 - iter 861/1233 - loss 0.60943082 - time (sec): 139.31 - samples/sec: 49.44 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 01:44:15,552 epoch 3 - iter 984/1233 - loss 0.60960876 - time (sec): 159.41 - samples/sec: 49.38 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 01:44:35,585 epoch 3 - iter 1107/1233 - loss 0.60743736 - time (sec): 179.44 - samples/sec: 49.35 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 01:44:55,746 epoch 3 - iter 1230/1233 - loss 0.60803533 - time (sec): 199.60 - samples/sec: 49.30 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 01:44:56,218 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:44:56,218 EPOCH 3 done: loss 0.6075 - lr: 0.000022\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.23it/s]\n",
      "2024-11-10 01:44:59,308 DEV : loss 0.652289628982544 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  3.97it/s]\n",
      "2024-11-10 01:45:02,809 TEST : loss 0.652289628982544 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:45:03,003 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:45:22,925 epoch 4 - iter 123/1233 - loss 0.64207490 - time (sec): 19.92 - samples/sec: 49.40 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 01:45:42,895 epoch 4 - iter 246/1233 - loss 0.61123030 - time (sec): 39.89 - samples/sec: 49.34 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:46:02,616 epoch 4 - iter 369/1233 - loss 0.60943512 - time (sec): 59.61 - samples/sec: 49.52 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 01:46:22,490 epoch 4 - iter 492/1233 - loss 0.60648189 - time (sec): 79.49 - samples/sec: 49.52 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 01:46:42,406 epoch 4 - iter 615/1233 - loss 0.59433764 - time (sec): 99.40 - samples/sec: 49.50 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 01:47:02,300 epoch 4 - iter 738/1233 - loss 0.60204630 - time (sec): 119.30 - samples/sec: 49.49 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 01:47:22,228 epoch 4 - iter 861/1233 - loss 0.59964816 - time (sec): 139.22 - samples/sec: 49.47 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 01:47:42,144 epoch 4 - iter 984/1233 - loss 0.60093547 - time (sec): 159.14 - samples/sec: 49.47 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 01:48:02,276 epoch 4 - iter 1107/1233 - loss 0.60113857 - time (sec): 179.27 - samples/sec: 49.40 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 01:48:22,260 epoch 4 - iter 1230/1233 - loss 0.59916310 - time (sec): 199.26 - samples/sec: 49.38 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 01:48:22,777 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:48:22,777 EPOCH 4 done: loss 0.5992 - lr: 0.000011\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.24it/s]\n",
      "2024-11-10 01:48:25,855 DEV : loss 0.6639564633369446 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.29it/s]\n",
      "2024-11-10 01:48:29,348 TEST : loss 0.6639564633369446 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:48:29,542 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:48:49,534 epoch 5 - iter 123/1233 - loss 0.59414472 - time (sec): 19.99 - samples/sec: 49.22 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:49:09,380 epoch 5 - iter 246/1233 - loss 0.59009342 - time (sec): 39.84 - samples/sec: 49.40 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 01:49:29,311 epoch 5 - iter 369/1233 - loss 0.60941239 - time (sec): 59.77 - samples/sec: 49.39 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 01:49:49,456 epoch 5 - iter 492/1233 - loss 0.59440069 - time (sec): 79.91 - samples/sec: 49.25 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 01:50:09,223 epoch 5 - iter 615/1233 - loss 0.59836967 - time (sec): 99.68 - samples/sec: 49.36 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 01:50:29,192 epoch 5 - iter 738/1233 - loss 0.60172556 - time (sec): 119.65 - samples/sec: 49.34 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 01:50:49,041 epoch 5 - iter 861/1233 - loss 0.59904770 - time (sec): 139.50 - samples/sec: 49.38 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 01:51:09,024 epoch 5 - iter 984/1233 - loss 0.60068875 - time (sec): 159.48 - samples/sec: 49.36 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 01:51:28,993 epoch 5 - iter 1107/1233 - loss 0.59725396 - time (sec): 179.45 - samples/sec: 49.35 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 01:51:48,752 epoch 5 - iter 1230/1233 - loss 0.60019637 - time (sec): 199.21 - samples/sec: 49.40 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 01:51:49,369 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:51:49,369 EPOCH 5 done: loss 0.5993 - lr: 0.000000\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.26it/s]\n",
      "2024-11-10 01:51:52,435 DEV : loss 0.6652141809463501 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.31it/s]\n",
      "2024-11-10 01:51:55,660 TEST : loss 0.6652141809463501 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:51:59,151 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:51:59,153 Testing using last state of model ...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:02<00:00,  4.34it/s]\n",
      "2024-11-10 01:52:02,159 \n",
      "Results:\n",
      "- F-score (micro) 0.7938\n",
      "- F-score (macro) 0.295\n",
      "- Accuracy 0.7938\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     –ù–æ—É—Ç–±—É–∫     0.7938    1.0000    0.8851       154\n",
      "      –°–µ—Ä–≤–µ—Ä     0.0000    0.0000    0.0000        29\n",
      "         –°–•–î     0.0000    0.0000    0.0000        11\n",
      "\n",
      "    accuracy                         0.7938       194\n",
      "   macro avg     0.2646    0.3333    0.2950       194\n",
      "weighted avg     0.6301    0.7938    0.7026       194\n",
      "\n",
      "2024-11-10 01:52:02,159 ----------------------------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:02<00:00, 10.00it/s]\n",
      "2024/11/10 01:52:25 INFO mlflow.tracking._tracking_service.client: üèÉ View run glamorous-hog-70 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/dceea6d5bc694f58bef4fae0ba5e436c.\n",
      "2024/11/10 01:52:25 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 01:52:31,988 Reading data from datav2\n",
      "2024-11-10 01:52:31,988 Train: datav2/train.csv\n",
      "2024-11-10 01:52:31,988 Dev: datav2/dev.csv\n",
      "2024-11-10 01:52:31,988 Test: datav2/test.csv\n",
      "2024-11-10 01:52:32,035 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1721.64it/s]\n",
      "2024-11-10 01:52:37,766 Dictionary created for label 'label' with 3 values: –ù–æ—É—Ç–±—É–∫ (seen 8130 times), –°–µ—Ä–≤–µ—Ä (seen 1075 times), –°–•–î (seen 655 times)\n",
      "2024-11-10 01:52:42,002 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,003 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(250003, 1024, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 01:52:42,003 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Train:  9860 sentences\n",
      "2024-11-10 01:52:42,004         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Training Params:\n",
      "2024-11-10 01:52:42,004  - learning_rate: \"5e-05\" \n",
      "2024-11-10 01:52:42,004  - mini_batch_size: \"8\"\n",
      "2024-11-10 01:52:42,004  - max_epochs: \"5\"\n",
      "2024-11-10 01:52:42,004  - shuffle: \"True\"\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Plugins:\n",
      "2024-11-10 01:52:42,004  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 01:52:42,004  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Computation:\n",
      "2024-11-10 01:52:42,004  - compute on device: cuda:0\n",
      "2024-11-10 01:52:42,004  - embedding storage: none\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Model training base path: \"modelsv2/datav2/intfloat_multilingual_e5_large\"\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:53:02,111 epoch 1 - iter 123/1233 - loss 0.33014339 - time (sec): 20.11 - samples/sec: 48.94 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:53:22,121 epoch 1 - iter 246/1233 - loss 0.17216167 - time (sec): 40.12 - samples/sec: 49.06 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:53:42,332 epoch 1 - iter 369/1233 - loss 0.11551793 - time (sec): 60.33 - samples/sec: 48.93 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:54:02,335 epoch 1 - iter 492/1233 - loss 0.09169493 - time (sec): 80.33 - samples/sec: 49.00 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:54:22,580 epoch 1 - iter 615/1233 - loss 0.07691794 - time (sec): 100.57 - samples/sec: 48.92 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 01:54:42,588 epoch 1 - iter 738/1233 - loss 0.06875369 - time (sec): 120.58 - samples/sec: 48.96 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 01:55:02,597 epoch 1 - iter 861/1233 - loss 0.06580578 - time (sec): 140.59 - samples/sec: 48.99 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 01:55:22,511 epoch 1 - iter 984/1233 - loss 0.05841207 - time (sec): 160.50 - samples/sec: 49.05 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 01:55:42,183 epoch 1 - iter 1107/1233 - loss 0.05192281 - time (sec): 180.18 - samples/sec: 49.15 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 01:56:02,414 epoch 1 - iter 1230/1233 - loss 0.05170570 - time (sec): 200.41 - samples/sec: 49.10 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 01:56:02,891 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:56:02,891 EPOCH 1 done: loss 0.0516 - lr: 0.000044\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.21it/s]\n",
      "2024-11-10 01:56:05,994 DEV : loss 0.22302745282649994 - f1-score (micro avg)  0.9845\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.03it/s]\n",
      "2024-11-10 01:56:09,426 TEST : loss 0.22302745282649994 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 01:56:09,622 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:56:29,355 epoch 2 - iter 123/1233 - loss 0.07942303 - time (sec): 19.73 - samples/sec: 49.87 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 01:56:49,440 epoch 2 - iter 246/1233 - loss 0.30398308 - time (sec): 39.82 - samples/sec: 49.43 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 01:57:09,234 epoch 2 - iter 369/1233 - loss 0.41364645 - time (sec): 59.61 - samples/sec: 49.52 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 01:57:29,207 epoch 2 - iter 492/1233 - loss 0.46812341 - time (sec): 79.58 - samples/sec: 49.46 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:57:49,255 epoch 2 - iter 615/1233 - loss 0.50203010 - time (sec): 99.63 - samples/sec: 49.38 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 01:58:09,601 epoch 2 - iter 738/1233 - loss 0.52549165 - time (sec): 119.98 - samples/sec: 49.21 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 01:58:29,547 epoch 2 - iter 861/1233 - loss 0.53410362 - time (sec): 139.92 - samples/sec: 49.23 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 01:58:49,921 epoch 2 - iter 984/1233 - loss 0.54526580 - time (sec): 160.30 - samples/sec: 49.11 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 01:59:10,183 epoch 2 - iter 1107/1233 - loss 0.55369879 - time (sec): 180.56 - samples/sec: 49.05 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 01:59:30,189 epoch 2 - iter 1230/1233 - loss 0.56993106 - time (sec): 200.57 - samples/sec: 49.06 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 01:59:30,678 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:59:30,679 EPOCH 2 done: loss 0.5699 - lr: 0.000033\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  3.96it/s]\n",
      "2024-11-10 01:59:33,973 DEV : loss 0.6741207838058472 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.25it/s]\n",
      "2024-11-10 01:59:37,259 TEST : loss 0.6741207838058472 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:59:37,463 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:59:57,474 epoch 3 - iter 123/1233 - loss 0.55449453 - time (sec): 20.01 - samples/sec: 49.18 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 02:00:17,553 epoch 3 - iter 246/1233 - loss 0.60498484 - time (sec): 40.09 - samples/sec: 49.09 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 02:00:37,866 epoch 3 - iter 369/1233 - loss 0.61595911 - time (sec): 60.40 - samples/sec: 48.87 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:00:58,026 epoch 3 - iter 492/1233 - loss 0.60760268 - time (sec): 80.56 - samples/sec: 48.86 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 02:01:18,240 epoch 3 - iter 615/1233 - loss 0.60903325 - time (sec): 100.78 - samples/sec: 48.82 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 02:01:38,271 epoch 3 - iter 738/1233 - loss 0.61385080 - time (sec): 120.81 - samples/sec: 48.87 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 02:01:58,229 epoch 3 - iter 861/1233 - loss 0.60862794 - time (sec): 140.77 - samples/sec: 48.93 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 02:02:18,326 epoch 3 - iter 984/1233 - loss 0.60867641 - time (sec): 160.86 - samples/sec: 48.94 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 02:02:38,257 epoch 3 - iter 1107/1233 - loss 0.60773768 - time (sec): 180.79 - samples/sec: 48.98 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 02:02:58,340 epoch 3 - iter 1230/1233 - loss 0.60937208 - time (sec): 200.88 - samples/sec: 48.99 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 02:02:58,782 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:02:58,782 EPOCH 3 done: loss 0.6096 - lr: 0.000022\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.23it/s]\n",
      "2024-11-10 02:03:01,870 DEV : loss 0.6529877185821533 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  3.98it/s]\n",
      "2024-11-10 02:03:05,344 TEST : loss 0.6529877185821533 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 02:03:05,582 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:03:25,697 epoch 4 - iter 123/1233 - loss 0.59127931 - time (sec): 20.11 - samples/sec: 48.92 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 02:03:45,824 epoch 4 - iter 246/1233 - loss 0.59136713 - time (sec): 40.24 - samples/sec: 48.91 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:04:06,077 epoch 4 - iter 369/1233 - loss 0.60359598 - time (sec): 60.49 - samples/sec: 48.80 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 02:04:26,167 epoch 4 - iter 492/1233 - loss 0.59508500 - time (sec): 80.58 - samples/sec: 48.84 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 02:04:46,154 epoch 4 - iter 615/1233 - loss 0.59910008 - time (sec): 100.57 - samples/sec: 48.92 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 02:05:06,284 epoch 4 - iter 738/1233 - loss 0.59841284 - time (sec): 120.70 - samples/sec: 48.91 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 02:05:26,613 epoch 4 - iter 861/1233 - loss 0.59787033 - time (sec): 141.03 - samples/sec: 48.84 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 02:05:46,489 epoch 4 - iter 984/1233 - loss 0.60111861 - time (sec): 160.90 - samples/sec: 48.92 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 02:06:06,653 epoch 4 - iter 1107/1233 - loss 0.60357341 - time (sec): 181.07 - samples/sec: 48.91 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 02:06:26,462 epoch 4 - iter 1230/1233 - loss 0.60532947 - time (sec): 200.88 - samples/sec: 48.98 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 02:06:26,955 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:06:26,955 EPOCH 4 done: loss 0.6048 - lr: 0.000011\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.22it/s]\n",
      "2024-11-10 02:06:30,046 DEV : loss 0.6393814086914062 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.26it/s]\n",
      "2024-11-10 02:06:33,480 TEST : loss 0.6393814086914062 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 02:06:33,679 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:06:53,746 epoch 5 - iter 123/1233 - loss 0.57926584 - time (sec): 20.06 - samples/sec: 49.04 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:07:13,875 epoch 5 - iter 246/1233 - loss 0.60402421 - time (sec): 40.19 - samples/sec: 48.96 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 02:07:33,826 epoch 5 - iter 369/1233 - loss 0.60360014 - time (sec): 60.15 - samples/sec: 49.08 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 02:07:54,015 epoch 5 - iter 492/1233 - loss 0.60284069 - time (sec): 80.33 - samples/sec: 49.00 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 02:08:14,033 epoch 5 - iter 615/1233 - loss 0.59736392 - time (sec): 100.35 - samples/sec: 49.03 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 02:08:34,061 epoch 5 - iter 738/1233 - loss 0.60246230 - time (sec): 120.38 - samples/sec: 49.04 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 02:08:53,930 epoch 5 - iter 861/1233 - loss 0.59912674 - time (sec): 140.25 - samples/sec: 49.11 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 02:09:14,082 epoch 5 - iter 984/1233 - loss 0.59870965 - time (sec): 160.40 - samples/sec: 49.08 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 02:09:33,917 epoch 5 - iter 1107/1233 - loss 0.59597039 - time (sec): 180.24 - samples/sec: 49.14 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 02:09:53,954 epoch 5 - iter 1230/1233 - loss 0.59671134 - time (sec): 200.27 - samples/sec: 49.13 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 02:09:54,423 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:09:54,423 EPOCH 5 done: loss 0.5964 - lr: 0.000000\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  3.98it/s]\n",
      "2024-11-10 02:09:57,704 DEV : loss 0.6447110772132874 - f1-score (micro avg)  0.7938\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.29it/s]\n",
      "2024-11-10 02:10:00,944 TEST : loss 0.6447110772132874 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 02:10:04,531 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:04,533 Testing using last state of model ...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:03<00:00,  4.05it/s]\n",
      "2024-11-10 02:10:07,758 \n",
      "Results:\n",
      "- F-score (micro) 0.7938\n",
      "- F-score (macro) 0.295\n",
      "- Accuracy 0.7938\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     –ù–æ—É—Ç–±—É–∫     0.7938    1.0000    0.8851       154\n",
      "      –°–µ—Ä–≤–µ—Ä     0.0000    0.0000    0.0000        29\n",
      "         –°–•–î     0.0000    0.0000    0.0000        11\n",
      "\n",
      "    accuracy                         0.7938       194\n",
      "   macro avg     0.2646    0.3333    0.2950       194\n",
      "weighted avg     0.6301    0.7938    0.7026       194\n",
      "\n",
      "2024-11-10 02:10:07,758 ----------------------------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:02<00:00,  9.97it/s]\n",
      "2024/11/10 02:10:31 INFO mlflow.tracking._tracking_service.client: üèÉ View run orderly-panda-894 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/cd55e610328946b48f2b6b7408e54387.\n",
      "2024/11/10 02:10:31 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 02:10:38,152 Reading data from datav2\n",
      "2024-11-10 02:10:38,152 Train: datav2/train.csv\n",
      "2024-11-10 02:10:38,152 Dev: datav2/dev.csv\n",
      "2024-11-10 02:10:38,152 Test: datav2/test.csv\n",
      "2024-11-10 02:10:38,199 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1769.80it/s]\n",
      "2024-11-10 02:10:43,775 Dictionary created for label 'label' with 3 values: –ù–æ—É—Ç–±—É–∫ (seen 8130 times), –°–µ—Ä–≤–µ—Ä (seen 1075 times), –°–•–î (seen 655 times)\n",
      "2024-11-10 02:10:46,389 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(250003, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 02:10:46,390 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 02:10:46,390 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Train:  9860 sentences\n",
      "2024-11-10 02:10:46,390         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 02:10:46,390 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Training Params:\n",
      "2024-11-10 02:10:46,390  - learning_rate: \"5e-05\" \n",
      "2024-11-10 02:10:46,390  - mini_batch_size: \"8\"\n",
      "2024-11-10 02:10:46,390  - max_epochs: \"5\"\n",
      "2024-11-10 02:10:46,390  - shuffle: \"True\"\n",
      "2024-11-10 02:10:46,390 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Plugins:\n",
      "2024-11-10 02:10:46,391  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,391 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 02:10:46,391  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,391 Computation:\n",
      "2024-11-10 02:10:46,391  - compute on device: cuda:0\n",
      "2024-11-10 02:10:46,391  - embedding storage: none\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,391 Model training base path: \"modelsv2/datav2/sentence_transformers_paraphrase_multilingual_mpnet_base_v2\"\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:55,005 epoch 1 - iter 123/1233 - loss 0.39104016 - time (sec): 8.61 - samples/sec: 114.24 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:11:03,235 epoch 1 - iter 246/1233 - loss 0.20077234 - time (sec): 16.84 - samples/sec: 116.84 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:11:11,542 epoch 1 - iter 369/1233 - loss 0.13406119 - time (sec): 25.15 - samples/sec: 117.37 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:11:20,073 epoch 1 - iter 492/1233 - loss 0.10560384 - time (sec): 33.68 - samples/sec: 116.86 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:11:28,035 epoch 1 - iter 615/1233 - loss 0.08664562 - time (sec): 41.64 - samples/sec: 118.15 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 02:11:36,180 epoch 1 - iter 738/1233 - loss 0.07441882 - time (sec): 49.79 - samples/sec: 118.58 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 02:11:44,585 epoch 1 - iter 861/1233 - loss 0.06426602 - time (sec): 58.19 - samples/sec: 118.36 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 02:11:52,704 epoch 1 - iter 984/1233 - loss 0.06164236 - time (sec): 66.31 - samples/sec: 118.71 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 02:12:00,770 epoch 1 - iter 1107/1233 - loss 0.05759510 - time (sec): 74.38 - samples/sec: 119.07 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 02:12:09,204 epoch 1 - iter 1230/1233 - loss 0.05395360 - time (sec): 82.81 - samples/sec: 118.82 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 02:12:09,413 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:12:09,413 EPOCH 1 done: loss 0.0538 - lr: 0.000044\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.75it/s]\n",
      "2024-11-10 02:12:10,637 DEV : loss 0.13859358429908752 - f1-score (micro avg)  0.9845\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.05it/s]\n",
      "2024-11-10 02:12:12,294 TEST : loss 0.13859358429908752 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:12:12,497 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:12:20,746 epoch 2 - iter 123/1233 - loss 0.00115031 - time (sec): 8.25 - samples/sec: 119.30 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 02:12:29,127 epoch 2 - iter 246/1233 - loss 0.01642727 - time (sec): 16.63 - samples/sec: 118.35 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 02:12:37,144 epoch 2 - iter 369/1233 - loss 0.01147204 - time (sec): 24.65 - samples/sec: 119.78 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 02:12:45,420 epoch 2 - iter 492/1233 - loss 0.00936473 - time (sec): 32.92 - samples/sec: 119.56 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:12:53,831 epoch 2 - iter 615/1233 - loss 0.00979342 - time (sec): 41.33 - samples/sec: 119.04 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 02:13:02,102 epoch 2 - iter 738/1233 - loss 0.00817568 - time (sec): 49.60 - samples/sec: 119.02 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 02:13:10,334 epoch 2 - iter 861/1233 - loss 0.00701287 - time (sec): 57.84 - samples/sec: 119.10 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 02:13:18,873 epoch 2 - iter 984/1233 - loss 0.01006569 - time (sec): 66.38 - samples/sec: 118.60 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 02:13:26,944 epoch 2 - iter 1107/1233 - loss 0.00896203 - time (sec): 74.45 - samples/sec: 118.96 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 02:13:35,183 epoch 2 - iter 1230/1233 - loss 0.00910660 - time (sec): 82.68 - samples/sec: 119.01 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 02:13:35,393 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:13:35,393 EPOCH 2 done: loss 0.0091 - lr: 0.000033\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.59it/s]\n",
      "2024-11-10 02:13:36,761 DEV : loss 0.11494137346744537 - f1-score (micro avg)  0.9845\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.26it/s]\n",
      "2024-11-10 02:13:38,120 TEST : loss 0.11494137346744537 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:13:38,314 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:13:46,709 epoch 3 - iter 123/1233 - loss 0.00005706 - time (sec): 8.39 - samples/sec: 117.22 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 02:13:54,516 epoch 3 - iter 246/1233 - loss 0.00466487 - time (sec): 16.20 - samples/sec: 121.47 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 02:14:02,381 epoch 3 - iter 369/1233 - loss 0.00313352 - time (sec): 24.07 - samples/sec: 122.66 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:14:10,544 epoch 3 - iter 492/1233 - loss 0.00236744 - time (sec): 32.23 - samples/sec: 122.12 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 02:14:18,646 epoch 3 - iter 615/1233 - loss 0.00380301 - time (sec): 40.33 - samples/sec: 121.99 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 02:14:26,786 epoch 3 - iter 738/1233 - loss 0.00317588 - time (sec): 48.47 - samples/sec: 121.80 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 02:14:35,121 epoch 3 - iter 861/1233 - loss 0.00426605 - time (sec): 56.81 - samples/sec: 121.25 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 02:14:43,170 epoch 3 - iter 984/1233 - loss 0.00422201 - time (sec): 64.85 - samples/sec: 121.38 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 02:14:51,334 epoch 3 - iter 1107/1233 - loss 0.00375608 - time (sec): 73.02 - samples/sec: 121.28 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 02:14:59,735 epoch 3 - iter 1230/1233 - loss 0.00338310 - time (sec): 81.42 - samples/sec: 120.85 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 02:14:59,919 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:14:59,919 EPOCH 3 done: loss 0.0034 - lr: 0.000022\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.08it/s]\n",
      "2024-11-10 02:15:01,105 DEV : loss 0.11303524672985077 - f1-score (micro avg)  0.9897\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.29it/s]\n",
      "2024-11-10 02:15:02,709 TEST : loss 0.11303524672985077 - f1-score (micro avg)  0.9897\n",
      "2024-11-10 02:15:02,902 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:15:11,163 epoch 4 - iter 123/1233 - loss 0.01922881 - time (sec): 8.26 - samples/sec: 119.14 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 02:15:19,807 epoch 4 - iter 246/1233 - loss 0.00964056 - time (sec): 16.90 - samples/sec: 116.42 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:15:27,970 epoch 4 - iter 369/1233 - loss 0.00901600 - time (sec): 25.07 - samples/sec: 117.77 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 02:15:36,016 epoch 4 - iter 492/1233 - loss 0.00678014 - time (sec): 33.11 - samples/sec: 118.87 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 02:15:44,379 epoch 4 - iter 615/1233 - loss 0.00546578 - time (sec): 41.48 - samples/sec: 118.62 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 02:15:52,206 epoch 4 - iter 738/1233 - loss 0.00457149 - time (sec): 49.30 - samples/sec: 119.75 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 02:16:00,297 epoch 4 - iter 861/1233 - loss 0.00392216 - time (sec): 57.39 - samples/sec: 120.01 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 02:16:08,748 epoch 4 - iter 984/1233 - loss 0.00347694 - time (sec): 65.85 - samples/sec: 119.55 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 02:16:17,047 epoch 4 - iter 1107/1233 - loss 0.00310812 - time (sec): 74.14 - samples/sec: 119.44 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 02:16:25,390 epoch 4 - iter 1230/1233 - loss 0.00330267 - time (sec): 82.49 - samples/sec: 119.29 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 02:16:25,588 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:16:25,588 EPOCH 4 done: loss 0.0033 - lr: 0.000011\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.14it/s]\n",
      "2024-11-10 02:16:27,023 DEV : loss 0.14037089049816132 - f1-score (micro avg)  0.9845\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.15it/s]\n",
      "2024-11-10 02:16:28,396 TEST : loss 0.14037089049816132 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:16:28,589 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:16:36,942 epoch 5 - iter 123/1233 - loss 0.00002140 - time (sec): 8.35 - samples/sec: 117.81 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:16:45,215 epoch 5 - iter 246/1233 - loss 0.00002136 - time (sec): 16.63 - samples/sec: 118.38 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 02:16:53,457 epoch 5 - iter 369/1233 - loss 0.00002103 - time (sec): 24.87 - samples/sec: 118.71 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 02:17:01,929 epoch 5 - iter 492/1233 - loss 0.00002070 - time (sec): 33.34 - samples/sec: 118.06 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 02:17:10,170 epoch 5 - iter 615/1233 - loss 0.00002051 - time (sec): 41.58 - samples/sec: 118.32 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 02:17:18,516 epoch 5 - iter 738/1233 - loss 0.00143747 - time (sec): 49.93 - samples/sec: 118.26 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 02:17:27,095 epoch 5 - iter 861/1233 - loss 0.00256953 - time (sec): 58.50 - samples/sec: 117.73 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 02:17:35,437 epoch 5 - iter 984/1233 - loss 0.00225090 - time (sec): 66.85 - samples/sec: 117.76 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 02:17:43,796 epoch 5 - iter 1107/1233 - loss 0.00200309 - time (sec): 75.21 - samples/sec: 117.76 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 02:17:52,006 epoch 5 - iter 1230/1233 - loss 0.00180493 - time (sec): 83.42 - samples/sec: 117.96 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 02:17:52,203 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:17:52,203 EPOCH 5 done: loss 0.0018 - lr: 0.000000\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.19it/s]\n",
      "2024-11-10 02:17:53,378 DEV : loss 0.14704376459121704 - f1-score (micro avg)  0.9845\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.47it/s]\n",
      "2024-11-10 02:17:54,962 TEST : loss 0.14704376459121704 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:17:56,985 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:17:56,986 Testing using last state of model ...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.22it/s]\n",
      "2024-11-10 02:17:58,156 \n",
      "Results:\n",
      "- F-score (micro) 0.9845\n",
      "- F-score (macro) 0.953\n",
      "- Accuracy 0.9845\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     –ù–æ—É—Ç–±—É–∫     0.9935    1.0000    0.9968       154\n",
      "      –°–µ—Ä–≤–µ—Ä     1.0000    0.8966    0.9455        29\n",
      "         –°–•–î     0.8462    1.0000    0.9167        11\n",
      "\n",
      "    accuracy                         0.9845       194\n",
      "   macro avg     0.9466    0.9655    0.9530       194\n",
      "weighted avg     0.9862    0.9845    0.9846       194\n",
      "\n",
      "2024-11-10 02:17:58,156 ----------------------------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 24.61it/s]\n",
      "2024/11/10 02:18:10 INFO mlflow.tracking._tracking_service.client: üèÉ View run popular-shad-817 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/9c7429bbe4124fda8de3aebd2e6d15d3.\n",
      "2024/11/10 02:18:10 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 02:18:17,014 Reading data from datav2\n",
      "2024-11-10 02:18:17,014 Train: datav2/train.csv\n",
      "2024-11-10 02:18:17,014 Dev: datav2/dev.csv\n",
      "2024-11-10 02:18:17,014 Test: datav2/test.csv\n",
      "2024-11-10 02:18:17,096 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1761.55it/s]\n",
      "2024-11-10 02:18:22,698 Dictionary created for label 'label' with 3 values: –ù–æ—É—Ç–±—É–∫ (seen 8130 times), –°–µ—Ä–≤–µ—Ä (seen 1075 times), –°–•–î (seen 655 times)\n",
      "2024-11-10 02:18:25,315 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,316 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(250003, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 02:18:25,316 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,316 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 02:18:25,316 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,316 Train:  9860 sentences\n",
      "2024-11-10 02:18:25,316         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 02:18:25,316 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,316 Training Params:\n",
      "2024-11-10 02:18:25,316  - learning_rate: \"5e-05\" \n",
      "2024-11-10 02:18:25,317  - mini_batch_size: \"8\"\n",
      "2024-11-10 02:18:25,317  - max_epochs: \"5\"\n",
      "2024-11-10 02:18:25,317  - shuffle: \"True\"\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 Plugins:\n",
      "2024-11-10 02:18:25,317  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 02:18:25,317  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 Computation:\n",
      "2024-11-10 02:18:25,317  - compute on device: cuda:0\n",
      "2024-11-10 02:18:25,317  - embedding storage: none\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 Model training base path: \"modelsv2/datav2/intfloat_multilingual_e5_base\"\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:33,560 epoch 1 - iter 123/1233 - loss 0.42792191 - time (sec): 8.24 - samples/sec: 119.38 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:18:41,443 epoch 1 - iter 246/1233 - loss 0.22592079 - time (sec): 16.12 - samples/sec: 122.05 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:18:49,551 epoch 1 - iter 369/1233 - loss 0.15647078 - time (sec): 24.23 - samples/sec: 121.82 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:18:57,437 epoch 1 - iter 492/1233 - loss 0.11839237 - time (sec): 32.12 - samples/sec: 122.54 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:19:05,274 epoch 1 - iter 615/1233 - loss 0.09479429 - time (sec): 39.96 - samples/sec: 123.14 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 02:19:13,385 epoch 1 - iter 738/1233 - loss 0.08040311 - time (sec): 48.07 - samples/sec: 122.83 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 02:19:21,170 epoch 1 - iter 861/1233 - loss 0.07144028 - time (sec): 55.85 - samples/sec: 123.32 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 02:19:29,001 epoch 1 - iter 984/1233 - loss 0.06277958 - time (sec): 63.68 - samples/sec: 123.61 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 02:19:36,990 epoch 1 - iter 1107/1233 - loss 0.05622661 - time (sec): 71.67 - samples/sec: 123.56 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 02:19:45,171 epoch 1 - iter 1230/1233 - loss 0.05067951 - time (sec): 79.85 - samples/sec: 123.23 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 02:19:45,376 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:19:45,377 EPOCH 1 done: loss 0.0506 - lr: 0.000044\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.80it/s]\n",
      "2024-11-10 02:19:46,597 DEV : loss 0.22020356357097626 - f1-score (micro avg)  0.9845\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.18it/s]\n",
      "2024-11-10 02:19:48,233 TEST : loss 0.22020356357097626 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:19:48,452 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:19:56,512 epoch 2 - iter 123/1233 - loss 0.00000144 - time (sec): 8.06 - samples/sec: 122.09 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 02:20:04,887 epoch 2 - iter 246/1233 - loss 0.00453423 - time (sec): 16.43 - samples/sec: 119.75 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 02:20:13,053 epoch 2 - iter 369/1233 - loss 0.00302313 - time (sec): 24.60 - samples/sec: 120.00 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 02:20:21,299 epoch 2 - iter 492/1233 - loss 0.00254611 - time (sec): 32.85 - samples/sec: 119.83 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:20:29,378 epoch 2 - iter 615/1233 - loss 0.00760857 - time (sec): 40.93 - samples/sec: 120.22 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 02:20:37,680 epoch 2 - iter 738/1233 - loss 0.01080632 - time (sec): 49.23 - samples/sec: 119.93 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 02:20:45,936 epoch 2 - iter 861/1233 - loss 0.01019677 - time (sec): 57.48 - samples/sec: 119.83 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 02:20:54,417 epoch 2 - iter 984/1233 - loss 0.00928950 - time (sec): 65.96 - samples/sec: 119.34 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 02:21:02,776 epoch 2 - iter 1107/1233 - loss 0.00826100 - time (sec): 74.32 - samples/sec: 119.16 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 02:21:11,158 epoch 2 - iter 1230/1233 - loss 0.01016852 - time (sec): 82.71 - samples/sec: 118.98 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 02:21:11,361 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:21:11,361 EPOCH 2 done: loss 0.0104 - lr: 0.000033\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.68it/s]\n",
      "2024-11-10 02:21:12,716 DEV : loss 0.3316602408885956 - f1-score (micro avg)  0.9639\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.87it/s]\n",
      "2024-11-10 02:21:14,120 TEST : loss 0.3316602408885956 - f1-score (micro avg)  0.9639\n",
      "2024-11-10 02:21:14,504 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:21:22,803 epoch 3 - iter 123/1233 - loss 0.00004842 - time (sec): 8.30 - samples/sec: 118.57 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 02:21:30,868 epoch 3 - iter 246/1233 - loss 0.00002449 - time (sec): 16.36 - samples/sec: 120.27 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 02:21:39,214 epoch 3 - iter 369/1233 - loss 0.00001680 - time (sec): 24.71 - samples/sec: 119.47 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:21:47,728 epoch 3 - iter 492/1233 - loss 0.00005719 - time (sec): 33.22 - samples/sec: 118.47 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 02:21:56,144 epoch 3 - iter 615/1233 - loss 0.00004627 - time (sec): 41.64 - samples/sec: 118.16 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 02:22:04,683 epoch 3 - iter 738/1233 - loss 0.00003863 - time (sec): 50.18 - samples/sec: 117.66 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 02:22:13,020 epoch 3 - iter 861/1233 - loss 0.00014664 - time (sec): 58.52 - samples/sec: 117.71 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 02:22:21,352 epoch 3 - iter 984/1233 - loss 0.00271622 - time (sec): 66.85 - samples/sec: 117.76 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 02:22:29,834 epoch 3 - iter 1107/1233 - loss 0.00300286 - time (sec): 75.33 - samples/sec: 117.56 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 02:22:38,036 epoch 3 - iter 1230/1233 - loss 0.00284235 - time (sec): 83.53 - samples/sec: 117.80 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 02:22:38,234 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:22:38,234 EPOCH 3 done: loss 0.0028 - lr: 0.000022\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.09it/s]\n",
      "2024-11-10 02:22:39,419 DEV : loss 0.2938547432422638 - f1-score (micro avg)  0.9794\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.02it/s]\n",
      "2024-11-10 02:22:41,082 TEST : loss 0.2938547432422638 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:22:41,290 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:22:49,425 epoch 4 - iter 123/1233 - loss 0.00000100 - time (sec): 8.13 - samples/sec: 120.97 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 02:22:57,851 epoch 4 - iter 246/1233 - loss 0.00000124 - time (sec): 16.56 - samples/sec: 118.84 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:23:05,732 epoch 4 - iter 369/1233 - loss 0.00000105 - time (sec): 24.44 - samples/sec: 120.78 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 02:23:13,899 epoch 4 - iter 492/1233 - loss 0.00000092 - time (sec): 32.61 - samples/sec: 120.71 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 02:23:22,456 epoch 4 - iter 615/1233 - loss 0.00000082 - time (sec): 41.17 - samples/sec: 119.52 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 02:23:30,816 epoch 4 - iter 738/1233 - loss 0.00000075 - time (sec): 49.53 - samples/sec: 119.21 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 02:23:39,112 epoch 4 - iter 861/1233 - loss 0.00177730 - time (sec): 57.82 - samples/sec: 119.13 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 02:23:47,348 epoch 4 - iter 984/1233 - loss 0.00179145 - time (sec): 66.06 - samples/sec: 119.17 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 02:23:55,552 epoch 4 - iter 1107/1233 - loss 0.00159392 - time (sec): 74.26 - samples/sec: 119.26 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 02:24:03,584 epoch 4 - iter 1230/1233 - loss 0.00143490 - time (sec): 82.29 - samples/sec: 119.57 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 02:24:03,773 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:24:03,774 EPOCH 4 done: loss 0.0014 - lr: 0.000011\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.48it/s]\n",
      "2024-11-10 02:24:05,157 DEV : loss 0.29005804657936096 - f1-score (micro avg)  0.9794\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.02it/s]\n",
      "2024-11-10 02:24:06,543 TEST : loss 0.29005804657936096 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:24:06,747 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:24:15,182 epoch 5 - iter 123/1233 - loss 0.00000242 - time (sec): 8.43 - samples/sec: 116.68 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:24:23,548 epoch 5 - iter 246/1233 - loss 0.00000199 - time (sec): 16.80 - samples/sec: 117.14 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 02:24:31,953 epoch 5 - iter 369/1233 - loss 0.00000192 - time (sec): 25.20 - samples/sec: 117.12 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 02:24:40,466 epoch 5 - iter 492/1233 - loss 0.00000395 - time (sec): 33.72 - samples/sec: 116.73 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 02:24:48,882 epoch 5 - iter 615/1233 - loss 0.00000342 - time (sec): 42.13 - samples/sec: 116.77 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 02:24:57,413 epoch 5 - iter 738/1233 - loss 0.00000310 - time (sec): 50.66 - samples/sec: 116.53 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 02:25:05,766 epoch 5 - iter 861/1233 - loss 0.00000281 - time (sec): 59.02 - samples/sec: 116.71 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 02:25:14,101 epoch 5 - iter 984/1233 - loss 0.00000262 - time (sec): 67.35 - samples/sec: 116.88 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 02:25:22,370 epoch 5 - iter 1107/1233 - loss 0.00000241 - time (sec): 75.62 - samples/sec: 117.11 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 02:25:30,700 epoch 5 - iter 1230/1233 - loss 0.00000228 - time (sec): 83.95 - samples/sec: 117.21 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 02:25:30,897 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:25:30,898 EPOCH 5 done: loss 0.0000 - lr: 0.000000\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.82it/s]\n",
      "2024-11-10 02:25:32,111 DEV : loss 0.2902233898639679 - f1-score (micro avg)  0.9794\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.32it/s]\n",
      "2024-11-10 02:25:33,714 TEST : loss 0.2902233898639679 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:25:35,755 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:25:35,756 Testing using last state of model ...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.20it/s]\n",
      "2024-11-10 02:25:36,929 \n",
      "Results:\n",
      "- F-score (micro) 0.9794\n",
      "- F-score (macro) 0.9403\n",
      "- Accuracy 0.9794\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     –ù–æ—É—Ç–±—É–∫     1.0000    0.9870    0.9935       154\n",
      "      –°–µ—Ä–≤–µ—Ä     0.9643    0.9310    0.9474        29\n",
      "         –°–•–î     0.7857    1.0000    0.8800        11\n",
      "\n",
      "    accuracy                         0.9794       194\n",
      "   macro avg     0.9167    0.9727    0.9403       194\n",
      "weighted avg     0.9825    0.9794    0.9801       194\n",
      "\n",
      "2024-11-10 02:25:36,929 ----------------------------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 19.61it/s]\n",
      "2024/11/10 02:25:50 INFO mlflow.tracking._tracking_service.client: üèÉ View run polite-rat-423 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/78964a2b90a84ff5aa6af1ebed2d5b8b.\n",
      "2024/11/10 02:25:50 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 02:25:56,275 Reading data from datav2\n",
      "2024-11-10 02:25:56,275 Train: datav2/train.csv\n",
      "2024-11-10 02:25:56,275 Dev: datav2/dev.csv\n",
      "2024-11-10 02:25:56,275 Test: datav2/test.csv\n",
      "2024-11-10 02:25:56,321 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1782.95it/s]\n",
      "2024-11-10 02:26:01,856 Dictionary created for label 'label' with 3 values: –ù–æ—É—Ç–±—É–∫ (seen 8130 times), –°–µ—Ä–≤–µ—Ä (seen 1075 times), –°–•–î (seen 655 times)\n",
      "2024-11-10 02:26:03,879 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,880 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(250038, 384, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 384)\n",
      "        (token_type_embeddings): Embedding(2, 384)\n",
      "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSdpaSelfAttention(\n",
      "                (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=384, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 02:26:03,880 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Train:  9860 sentences\n",
      "2024-11-10 02:26:03,881         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Training Params:\n",
      "2024-11-10 02:26:03,881  - learning_rate: \"5e-05\" \n",
      "2024-11-10 02:26:03,881  - mini_batch_size: \"8\"\n",
      "2024-11-10 02:26:03,881  - max_epochs: \"5\"\n",
      "2024-11-10 02:26:03,881  - shuffle: \"True\"\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Plugins:\n",
      "2024-11-10 02:26:03,881  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 02:26:03,881  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Computation:\n",
      "2024-11-10 02:26:03,881  - compute on device: cuda:0\n",
      "2024-11-10 02:26:03,881  - embedding storage: none\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Model training base path: \"modelsv2/datav2/intfloat_multilingual_e5_small\"\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:10,899 epoch 1 - iter 123/1233 - loss 0.65520835 - time (sec): 7.02 - samples/sec: 140.24 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:26:17,603 epoch 1 - iter 246/1233 - loss 0.37084727 - time (sec): 13.72 - samples/sec: 143.43 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:26:24,659 epoch 1 - iter 369/1233 - loss 0.25248048 - time (sec): 20.78 - samples/sec: 142.08 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:26:31,694 epoch 1 - iter 492/1233 - loss 0.19237101 - time (sec): 27.81 - samples/sec: 141.52 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:26:38,695 epoch 1 - iter 615/1233 - loss 0.15484049 - time (sec): 34.81 - samples/sec: 141.33 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 02:26:44,549 epoch 1 - iter 738/1233 - loss 0.12918834 - time (sec): 40.67 - samples/sec: 145.18 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 02:26:50,768 epoch 1 - iter 861/1233 - loss 0.11452456 - time (sec): 46.89 - samples/sec: 146.91 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 02:26:57,671 epoch 1 - iter 984/1233 - loss 0.10094000 - time (sec): 53.79 - samples/sec: 146.35 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 02:27:04,457 epoch 1 - iter 1107/1233 - loss 0.09050530 - time (sec): 60.57 - samples/sec: 146.20 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 02:27:11,246 epoch 1 - iter 1230/1233 - loss 0.08205343 - time (sec): 67.36 - samples/sec: 146.07 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 02:27:11,412 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:27:11,412 EPOCH 1 done: loss 0.0819 - lr: 0.000044\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 18.50it/s]\n",
      "2024-11-10 02:27:12,128 DEV : loss 0.09091053158044815 - f1-score (micro avg)  0.9845\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 15.04it/s]\n",
      "2024-11-10 02:27:13,197 TEST : loss 0.09091053158044815 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:27:13,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:27:19,003 epoch 2 - iter 123/1233 - loss 0.00051474 - time (sec): 5.61 - samples/sec: 175.37 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 02:27:23,620 epoch 2 - iter 246/1233 - loss 0.00104492 - time (sec): 10.23 - samples/sec: 192.42 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 02:27:28,066 epoch 2 - iter 369/1233 - loss 0.00139149 - time (sec): 14.67 - samples/sec: 201.18 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 02:27:32,467 epoch 2 - iter 492/1233 - loss 0.00337955 - time (sec): 19.07 - samples/sec: 206.35 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:27:38,172 epoch 2 - iter 615/1233 - loss 0.00379502 - time (sec): 24.78 - samples/sec: 198.55 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 02:27:44,504 epoch 2 - iter 738/1233 - loss 0.00322894 - time (sec): 31.11 - samples/sec: 189.77 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 02:27:51,088 epoch 2 - iter 861/1233 - loss 0.00281891 - time (sec): 37.70 - samples/sec: 182.72 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 02:27:56,254 epoch 2 - iter 984/1233 - loss 0.00250717 - time (sec): 42.86 - samples/sec: 183.66 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 02:28:02,140 epoch 2 - iter 1107/1233 - loss 0.00226317 - time (sec): 48.75 - samples/sec: 181.67 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 02:28:07,558 epoch 2 - iter 1230/1233 - loss 0.00206693 - time (sec): 54.17 - samples/sec: 181.67 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 02:28:07,663 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:28:07,664 EPOCH 2 done: loss 0.0021 - lr: 0.000033\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 14.44it/s]\n",
      "2024-11-10 02:28:08,576 DEV : loss 0.07282549142837524 - f1-score (micro avg)  0.9897\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 17.71it/s]\n",
      "2024-11-10 02:28:09,533 TEST : loss 0.07282549142837524 - f1-score (micro avg)  0.9897\n",
      "2024-11-10 02:28:09,958 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:28:15,442 epoch 3 - iter 123/1233 - loss 0.00028646 - time (sec): 5.48 - samples/sec: 179.45 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 02:28:20,807 epoch 3 - iter 246/1233 - loss 0.00027269 - time (sec): 10.85 - samples/sec: 181.40 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 02:28:26,429 epoch 3 - iter 369/1233 - loss 0.00026517 - time (sec): 16.47 - samples/sec: 179.23 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:28:32,249 epoch 3 - iter 492/1233 - loss 0.00025870 - time (sec): 22.29 - samples/sec: 176.58 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 02:28:37,459 epoch 3 - iter 615/1233 - loss 0.00025202 - time (sec): 27.50 - samples/sec: 178.91 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 02:28:43,011 epoch 3 - iter 738/1233 - loss 0.00024741 - time (sec): 33.05 - samples/sec: 178.63 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 02:28:48,658 epoch 3 - iter 861/1233 - loss 0.00341898 - time (sec): 38.70 - samples/sec: 177.99 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 02:28:54,133 epoch 3 - iter 984/1233 - loss 0.00368798 - time (sec): 44.17 - samples/sec: 178.20 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 02:28:58,761 epoch 3 - iter 1107/1233 - loss 0.00403305 - time (sec): 48.80 - samples/sec: 181.47 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 02:29:03,656 epoch 3 - iter 1230/1233 - loss 0.00364976 - time (sec): 53.70 - samples/sec: 183.25 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 02:29:03,815 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:29:03,816 EPOCH 3 done: loss 0.0036 - lr: 0.000022\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 18.76it/s]\n",
      "2024-11-10 02:29:04,521 DEV : loss 0.13201873004436493 - f1-score (micro avg)  0.9742\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 17.93it/s]\n",
      "2024-11-10 02:29:05,672 TEST : loss 0.13201873004436493 - f1-score (micro avg)  0.9742\n",
      "2024-11-10 02:29:05,867 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:29:11,907 epoch 4 - iter 123/1233 - loss 0.00017645 - time (sec): 6.04 - samples/sec: 162.94 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 02:29:18,385 epoch 4 - iter 246/1233 - loss 0.00017545 - time (sec): 12.52 - samples/sec: 157.23 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:29:23,830 epoch 4 - iter 369/1233 - loss 0.00017378 - time (sec): 17.96 - samples/sec: 164.35 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 02:29:29,580 epoch 4 - iter 492/1233 - loss 0.00017301 - time (sec): 23.71 - samples/sec: 165.99 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 02:29:36,227 epoch 4 - iter 615/1233 - loss 0.00017140 - time (sec): 30.36 - samples/sec: 162.06 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 02:29:42,984 epoch 4 - iter 738/1233 - loss 0.00016777 - time (sec): 37.12 - samples/sec: 159.07 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 02:29:48,707 epoch 4 - iter 861/1233 - loss 0.00016414 - time (sec): 42.84 - samples/sec: 160.79 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 02:29:54,850 epoch 4 - iter 984/1233 - loss 0.00016081 - time (sec): 48.98 - samples/sec: 160.71 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 02:30:01,376 epoch 4 - iter 1107/1233 - loss 0.00015886 - time (sec): 55.51 - samples/sec: 159.54 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 02:30:07,836 epoch 4 - iter 1230/1233 - loss 0.00015677 - time (sec): 61.97 - samples/sec: 158.79 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 02:30:07,978 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:30:07,978 EPOCH 4 done: loss 0.0002 - lr: 0.000011\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 14.65it/s]\n",
      "2024-11-10 02:30:08,878 DEV : loss 0.13009817898273468 - f1-score (micro avg)  0.9794\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 19.06it/s]\n",
      "2024-11-10 02:30:09,767 TEST : loss 0.13009817898273468 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:30:09,974 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:30:16,415 epoch 5 - iter 123/1233 - loss 0.00013440 - time (sec): 6.44 - samples/sec: 152.80 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:30:23,245 epoch 5 - iter 246/1233 - loss 0.00013202 - time (sec): 13.27 - samples/sec: 148.30 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 02:30:29,479 epoch 5 - iter 369/1233 - loss 0.00013038 - time (sec): 19.50 - samples/sec: 151.35 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 02:30:34,868 epoch 5 - iter 492/1233 - loss 0.00012758 - time (sec): 24.89 - samples/sec: 158.11 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 02:30:40,433 epoch 5 - iter 615/1233 - loss 0.00012583 - time (sec): 30.46 - samples/sec: 161.53 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 02:30:46,361 epoch 5 - iter 738/1233 - loss 0.00012480 - time (sec): 36.39 - samples/sec: 162.26 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 02:30:51,667 epoch 5 - iter 861/1233 - loss 0.00012343 - time (sec): 41.69 - samples/sec: 165.21 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 02:30:56,835 epoch 5 - iter 984/1233 - loss 0.00012281 - time (sec): 46.86 - samples/sec: 167.99 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 02:31:02,604 epoch 5 - iter 1107/1233 - loss 0.00012158 - time (sec): 52.63 - samples/sec: 168.27 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 02:31:07,480 epoch 5 - iter 1230/1233 - loss 0.00012091 - time (sec): 57.51 - samples/sec: 171.11 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 02:31:07,608 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:31:07,608 EPOCH 5 done: loss 0.0001 - lr: 0.000000\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 18.36it/s]\n",
      "2024-11-10 02:31:08,328 DEV : loss 0.12319633364677429 - f1-score (micro avg)  0.9794\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 13.07it/s]\n",
      "2024-11-10 02:31:09,527 TEST : loss 0.12319633364677429 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:31:10,664 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:31:10,665 Testing using last state of model ...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 18.98it/s]\n",
      "2024-11-10 02:31:11,362 \n",
      "Results:\n",
      "- F-score (micro) 0.9794\n",
      "- F-score (macro) 0.9471\n",
      "- Accuracy 0.9794\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     –ù–æ—É—Ç–±—É–∫     1.0000    0.9870    0.9935       154\n",
      "      –°–µ—Ä–≤–µ—Ä     0.9310    0.9310    0.9310        29\n",
      "         –°–•–î     0.8462    1.0000    0.9167        11\n",
      "\n",
      "    accuracy                         0.9794       194\n",
      "   macro avg     0.9257    0.9727    0.9471       194\n",
      "weighted avg     0.9810    0.9794    0.9798       194\n",
      "\n",
      "2024-11-10 02:31:11,362 ----------------------------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 27.21it/s]\n",
      "2024/11/10 02:31:18 INFO mlflow.tracking._tracking_service.client: üèÉ View run enchanting-grub-126 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/332304d8b4bc422ba3bd573a2c400e9f.\n",
      "2024/11/10 02:31:18 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n"
     ]
    }
   ],
   "source": [
    "model_names = [ 'deepvk/USER-bge-m3', 'deepvk/USER-base',\n",
    "               'intfloat/multilingual-e5-large-instruct', 'intfloat/multilingual-e5-large',\n",
    "               'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'intfloat/multilingual-e5-base', 'intfloat/multilingual-e5-small', \n",
    "               ]\n",
    "script_name = \"main.py\"\n",
    "for model in model_names:\n",
    "    data_folder='./datav2/'\n",
    "    experiment = '–¢–∏–ø_–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è_data_v2.0_expanded_data'\n",
    "    model_name = model\n",
    "    learning_rate = 5.0e-5\n",
    "    mini_batch_size = 8\n",
    "    max_epochs = 5\n",
    "    \n",
    "    command = f\"python {script_name} --experiment {experiment} --data_folder {data_folder} --model_name {model_name} --learning_rate {learning_rate} --mini_batch_size {mini_batch_size} --max_epochs {max_epochs}\"\n",
    "    !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519690ea-4e02-43c7-86a3-cd037ea75ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [ 'deepvk/USER-bge-m3', 'deepvk/USER-base',\n",
    "               'intfloat/multilingual-e5-large-instruct', 'intfloat/multilingual-e5-large',\n",
    "               'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'intfloat/multilingual-e5-base',\n",
    "               'sergeyzh/rubert-tiny-turbo', 'intfloat/multilingual-e5-small', \n",
    "               \"FacebookAI/xlm-roberta-large\"\n",
    "               ]\n",
    "script_name = \"main.py\"\n",
    "for model in model_names:\n",
    "    data_folder='./datav2/'\n",
    "    experiment = '–¢–∏–ø_–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è_data_v2.0_expanded_data'\n",
    "    model_name = model\n",
    "    learning_rate = 5.0e-5\n",
    "    mini_batch_size = 8\n",
    "    max_epochs = 5\n",
    "    \n",
    "    command = f\"python {script_name} --experiment {experiment} --data_folder {data_folder} --model_name {model_name} --learning_rate {learning_rate} --mini_batch_size {mini_batch_size} --max_epochs {max_epochs}\"\n",
    "    !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b9d3a-3b5d-4944-8326-047d04823f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14adf762-4774-4f9d-a12b-6d4af0318658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64924e49-783a-4b80-a2e7-a7f455e1ed96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31791f1-6669-4cca-9d12-348e31b035e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'deepvk/USER-bge-m3', 'deepvk/USER-base',\n",
    "               'intfloat/multilingual-e5-large-instruct', 'intfloat/multilingual-e5-large',\n",
    "               'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'intfloat/multilingual-e5-base',\n",
    "               'sergeyzh/rubert-tiny-turbo', 'intfloat/multilingual-e5-small', \n",
    "               \"FacebookAI/xlm-roberta-large\", \"yandex/RuLeanALBERT\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561850c-2499-475d-94ac-124785670917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294d771-4d3c-48e9-a81e-c5d81ec36a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b0d156-8439-4147-9170-f83a52ba5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ad260c9-e63a-49ce-93fa-9e20843baa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>–ù–µ –ø–æ–¥–∞–µ—Ç—Å—è –ø–∏—Ç–∞–Ω–∏–µ –Ω–∞ –Ω–æ—É—Ç–±—É–∫ [SEP] –ú–æ–π –±–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏—è –¥–ª—è –Ω–æ—É—Ç–±—É–∫–∞ ACER –ø–µ—Ä–µ—Å—Ç–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å. –ù–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∏ –ø—Ä–∏ –∫–∞–∫–∏—Ö –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞—Ö.</th>\n",
       "      <th>–ù–æ—É—Ç–±—É–∫</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ü—Ä–æ–±–ª–µ–º—ã —Å –∑–∞—Ä—è–¥–∫–æ–π –Ω–æ—É—Ç–±—É–∫–∞ [SEP] –ë–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏...</td>\n",
       "      <td>–ù–æ—É—Ç–±—É–∫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ë–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏—è –Ω–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è [SEP] –í–¥—Ä—É–≥ –ø–µ—Ä–µ—Å—Ç–∞...</td>\n",
       "      <td>–ù–æ—É—Ç–±—É–∫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ù–æ—É—Ç–±—É–∫ –Ω–µ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ø–∏—Ç–∞–Ω–∏—è [S...</td>\n",
       "      <td>–ù–æ—É—Ç–±—É–∫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ù–µ —É–¥–∞–µ—Ç—Å—è –∑–∞—Ä—è–¥–∏—Ç—å –Ω–æ—É—Ç–±—É–∫ [SEP] –ë–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏—è...</td>\n",
       "      <td>–ù–æ—É—Ç–±—É–∫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ù–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç—å –±–ª–æ–∫–∞ –ø–∏—Ç–∞–Ω–∏—è [SEP] –ú–æ–π –±–ª–æ–∫ –ø–∏—Ç...</td>\n",
       "      <td>–ù–æ—É—Ç–±—É–∫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>–û—à–∏–±–∫–∏ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã [SEP] –ó–¥—Ä–∞–≤—Å—Ç–≤...</td>\n",
       "      <td>–°–µ—Ä–≤–µ—Ä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>–ü—Ä–æ–±–ª–µ–º—ã —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è [SE...</td>\n",
       "      <td>–°–µ—Ä–≤–µ—Ä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>–ó–∞–ø—Ä–æ—Å –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Ç–µ–≤—ã—Ö –¥—Ä–∞–π–≤–µ—Ä–æ–≤ [SEP] –ó...</td>\n",
       "      <td>–°–µ—Ä–≤–µ—Ä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞ [S...</td>\n",
       "      <td>–°–µ—Ä–≤–µ—Ä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>–û—à–∏–±–∫–∏ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è BMC [SEP] –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ...</td>\n",
       "      <td>–°–µ—Ä–≤–µ—Ä</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     –ù–µ –ø–æ–¥–∞–µ—Ç—Å—è –ø–∏—Ç–∞–Ω–∏–µ –Ω–∞ –Ω–æ—É—Ç–±—É–∫ [SEP] –ú–æ–π –±–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏—è –¥–ª—è –Ω–æ—É—Ç–±—É–∫–∞ ACER –ø–µ—Ä–µ—Å—Ç–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å. –ù–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∏ –ø—Ä–∏ –∫–∞–∫–∏—Ö –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞—Ö.  \\\n",
       "0     –ü—Ä–æ–±–ª–µ–º—ã —Å –∑–∞—Ä—è–¥–∫–æ–π –Ω–æ—É—Ç–±—É–∫–∞ [SEP] –ë–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏...                                                                                       \n",
       "1     –ë–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏—è –Ω–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è [SEP] –í–¥—Ä—É–≥ –ø–µ—Ä–µ—Å—Ç–∞...                                                                                       \n",
       "2     –ù–æ—É—Ç–±—É–∫ –Ω–µ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ø–∏—Ç–∞–Ω–∏—è [S...                                                                                       \n",
       "3     –ù–µ —É–¥–∞–µ—Ç—Å—è –∑–∞—Ä—è–¥–∏—Ç—å –Ω–æ—É—Ç–±—É–∫ [SEP] –ë–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏—è...                                                                                       \n",
       "4     –ù–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç—å –±–ª–æ–∫–∞ –ø–∏—Ç–∞–Ω–∏—è [SEP] –ú–æ–π –±–ª–æ–∫ –ø–∏—Ç...                                                                                       \n",
       "...                                                 ...                                                                                       \n",
       "1634  –û—à–∏–±–∫–∏ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã [SEP] –ó–¥—Ä–∞–≤—Å—Ç–≤...                                                                                       \n",
       "1635  –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è [SE...                                                                                       \n",
       "1636  –ó–∞–ø—Ä–æ—Å –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Ç–µ–≤—ã—Ö –¥—Ä–∞–π–≤–µ—Ä–æ–≤ [SEP] –ó...                                                                                       \n",
       "1637  –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞ [S...                                                                                       \n",
       "1638  –û—à–∏–±–∫–∏ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è BMC [SEP] –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ...                                                                                       \n",
       "\n",
       "      –ù–æ—É—Ç–±—É–∫  \n",
       "0     –ù–æ—É—Ç–±—É–∫  \n",
       "1     –ù–æ—É—Ç–±—É–∫  \n",
       "2     –ù–æ—É—Ç–±—É–∫  \n",
       "3     –ù–æ—É—Ç–±—É–∫  \n",
       "4     –ù–æ—É—Ç–±—É–∫  \n",
       "...       ...  \n",
       "1634   –°–µ—Ä–≤–µ—Ä  \n",
       "1635   –°–µ—Ä–≤–µ—Ä  \n",
       "1636   –°–µ—Ä–≤–µ—Ä  \n",
       "1637   –°–µ—Ä–≤–µ—Ä  \n",
       "1638   –°–µ—Ä–≤–µ—Ä  \n",
       "\n",
       "[1639 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/train.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47beffac-1bda-47cd-8446-5e3975d48d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
