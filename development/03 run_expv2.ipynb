{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a60077-2b1e-4dd6-aee5-3aba869511e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/11/10 01:10:05 INFO mlflow.tracking.fluent: Experiment with name 'Тип_оборудования_data_v2.0_expanded_data' does not exist. Creating a new experiment.\n",
      "2024-11-10 01:10:05,587 Reading data from datav2\n",
      "2024-11-10 01:10:05,587 Train: datav2/train.csv\n",
      "2024-11-10 01:10:05,587 Dev: datav2/dev.csv\n",
      "2024-11-10 01:10:05,587 Test: datav2/test.csv\n",
      "2024-11-10 01:10:05,632 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1770.96it/s]\n",
      "2024-11-10 01:10:11,204 Dictionary created for label 'label' with 3 values: Ноутбук (seen 8130 times), Сервер (seen 1075 times), СХД (seen 655 times)\n",
      "2024-11-10 01:10:13,600 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(46167, 1024, padding_idx=1)\n",
      "        (position_embeddings): Embedding(8194, 1024, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 01:10:13,602 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 01:10:13,602 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Train:  9860 sentences\n",
      "2024-11-10 01:10:13,602         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 01:10:13,602 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Training Params:\n",
      "2024-11-10 01:10:13,602  - learning_rate: \"5e-05\" \n",
      "2024-11-10 01:10:13,602  - mini_batch_size: \"8\"\n",
      "2024-11-10 01:10:13,602  - max_epochs: \"5\"\n",
      "2024-11-10 01:10:13,602  - shuffle: \"True\"\n",
      "2024-11-10 01:10:13,602 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,602 Plugins:\n",
      "2024-11-10 01:10:13,602  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,603 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 01:10:13,603  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,603 Computation:\n",
      "2024-11-10 01:10:13,603  - compute on device: cuda:0\n",
      "2024-11-10 01:10:13,603  - embedding storage: none\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,603 Model training base path: \"modelsv2/datav2/deepvk_USER_bge_m3\"\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:13,603 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:10:30,475 epoch 1 - iter 123/1233 - loss 0.30254450 - time (sec): 16.87 - samples/sec: 58.32 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:10:47,358 epoch 1 - iter 246/1233 - loss 0.16418342 - time (sec): 33.75 - samples/sec: 58.31 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:11:04,482 epoch 1 - iter 369/1233 - loss 0.12309941 - time (sec): 50.88 - samples/sec: 58.02 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:11:21,394 epoch 1 - iter 492/1233 - loss 0.09244829 - time (sec): 67.79 - samples/sec: 58.06 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:11:38,604 epoch 1 - iter 615/1233 - loss 0.08023119 - time (sec): 85.00 - samples/sec: 57.88 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 01:11:55,532 epoch 1 - iter 738/1233 - loss 0.07664285 - time (sec): 101.93 - samples/sec: 57.92 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 01:12:12,653 epoch 1 - iter 861/1233 - loss 0.06917857 - time (sec): 119.05 - samples/sec: 57.86 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 01:12:29,759 epoch 1 - iter 984/1233 - loss 0.06328982 - time (sec): 136.15 - samples/sec: 57.82 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 01:12:46,858 epoch 1 - iter 1107/1233 - loss 0.05626861 - time (sec): 153.25 - samples/sec: 57.79 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 01:13:03,808 epoch 1 - iter 1230/1233 - loss 0.05340093 - time (sec): 170.20 - samples/sec: 57.81 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 01:13:04,217 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:13:04,217 EPOCH 1 done: loss 0.0533 - lr: 0.000044\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:13:15,749 DEV : loss 0.28919607400894165 - f1-score (micro avg)  0.9845\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:13:27,641 TEST : loss 0.28919607400894165 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 01:13:27,834 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:13:44,556 epoch 2 - iter 123/1233 - loss 0.00825536 - time (sec): 16.72 - samples/sec: 58.85 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 01:14:01,707 epoch 2 - iter 246/1233 - loss 0.01371782 - time (sec): 33.87 - samples/sec: 58.10 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 01:14:18,726 epoch 2 - iter 369/1233 - loss 0.02144445 - time (sec): 50.89 - samples/sec: 58.01 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 01:14:35,931 epoch 2 - iter 492/1233 - loss 0.02544656 - time (sec): 68.09 - samples/sec: 57.80 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:14:52,727 epoch 2 - iter 615/1233 - loss 0.03741904 - time (sec): 84.89 - samples/sec: 57.96 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 01:15:09,770 epoch 2 - iter 738/1233 - loss 0.18434652 - time (sec): 101.93 - samples/sec: 57.92 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 01:15:26,668 epoch 2 - iter 861/1233 - loss 0.25613014 - time (sec): 118.83 - samples/sec: 57.96 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 01:15:43,507 epoch 2 - iter 984/1233 - loss 0.31246242 - time (sec): 135.67 - samples/sec: 58.02 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 01:16:00,554 epoch 2 - iter 1107/1233 - loss 0.34549953 - time (sec): 152.72 - samples/sec: 57.99 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 01:16:17,701 epoch 2 - iter 1230/1233 - loss 0.37497546 - time (sec): 169.86 - samples/sec: 57.93 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 01:16:18,115 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:16:18,115 EPOCH 2 done: loss 0.3755 - lr: 0.000033\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.12it/s]\n",
      "2024-11-10 01:16:29,787 DEV : loss 0.6520723104476929 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:16:41,462 TEST : loss 0.6520723104476929 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:16:41,654 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:16:58,678 epoch 3 - iter 123/1233 - loss 0.62773801 - time (sec): 17.02 - samples/sec: 57.80 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 01:17:15,760 epoch 3 - iter 246/1233 - loss 0.62210512 - time (sec): 34.10 - samples/sec: 57.71 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 01:17:33,004 epoch 3 - iter 369/1233 - loss 0.61318264 - time (sec): 51.35 - samples/sec: 57.49 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:17:50,105 epoch 3 - iter 492/1233 - loss 0.60941451 - time (sec): 68.45 - samples/sec: 57.50 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 01:18:07,211 epoch 3 - iter 615/1233 - loss 0.60524674 - time (sec): 85.56 - samples/sec: 57.51 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 01:18:24,332 epoch 3 - iter 738/1233 - loss 0.60758326 - time (sec): 102.68 - samples/sec: 57.50 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 01:18:41,672 epoch 3 - iter 861/1233 - loss 0.60624155 - time (sec): 120.02 - samples/sec: 57.39 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 01:18:58,792 epoch 3 - iter 984/1233 - loss 0.60779014 - time (sec): 137.14 - samples/sec: 57.40 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 01:19:15,755 epoch 3 - iter 1107/1233 - loss 0.61046526 - time (sec): 154.10 - samples/sec: 57.47 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 01:19:32,986 epoch 3 - iter 1230/1233 - loss 0.61286036 - time (sec): 171.33 - samples/sec: 57.43 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 01:19:33,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:19:33,391 EPOCH 3 done: loss 0.6131 - lr: 0.000022\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:19:44,895 DEV : loss 0.641645610332489 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.10it/s]\n",
      "2024-11-10 01:19:56,869 TEST : loss 0.641645610332489 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:19:57,089 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:20:14,136 epoch 4 - iter 123/1233 - loss 0.59894515 - time (sec): 17.04 - samples/sec: 57.73 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 01:20:31,304 epoch 4 - iter 246/1233 - loss 0.61325126 - time (sec): 34.21 - samples/sec: 57.52 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:20:48,334 epoch 4 - iter 369/1233 - loss 0.60893877 - time (sec): 51.24 - samples/sec: 57.61 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 01:21:05,362 epoch 4 - iter 492/1233 - loss 0.60482420 - time (sec): 68.27 - samples/sec: 57.65 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 01:21:22,399 epoch 4 - iter 615/1233 - loss 0.59883779 - time (sec): 85.31 - samples/sec: 57.67 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 01:21:39,321 epoch 4 - iter 738/1233 - loss 0.59955653 - time (sec): 102.23 - samples/sec: 57.75 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 01:21:56,538 epoch 4 - iter 861/1233 - loss 0.59304641 - time (sec): 119.45 - samples/sec: 57.67 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 01:22:13,542 epoch 4 - iter 984/1233 - loss 0.59566032 - time (sec): 136.45 - samples/sec: 57.69 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 01:22:30,678 epoch 4 - iter 1107/1233 - loss 0.60190442 - time (sec): 153.59 - samples/sec: 57.66 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 01:22:47,766 epoch 4 - iter 1230/1233 - loss 0.60396732 - time (sec): 170.68 - samples/sec: 57.65 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 01:22:48,160 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:22:48,160 EPOCH 4 done: loss 0.6038 - lr: 0.000011\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:22:59,680 DEV : loss 0.632508397102356 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:23:11,636 TEST : loss 0.632508397102356 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:23:11,837 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:23:28,941 epoch 5 - iter 123/1233 - loss 0.62867308 - time (sec): 17.10 - samples/sec: 57.54 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:23:45,914 epoch 5 - iter 246/1233 - loss 0.62175294 - time (sec): 34.08 - samples/sec: 57.75 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 01:24:02,947 epoch 5 - iter 369/1233 - loss 0.59398581 - time (sec): 51.11 - samples/sec: 57.76 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 01:24:20,197 epoch 5 - iter 492/1233 - loss 0.58551403 - time (sec): 68.36 - samples/sec: 57.58 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 01:24:37,204 epoch 5 - iter 615/1233 - loss 0.58634525 - time (sec): 85.37 - samples/sec: 57.63 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 01:24:54,610 epoch 5 - iter 738/1233 - loss 0.59264108 - time (sec): 102.77 - samples/sec: 57.45 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 01:25:11,663 epoch 5 - iter 861/1233 - loss 0.59540056 - time (sec): 119.82 - samples/sec: 57.48 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 01:25:28,922 epoch 5 - iter 984/1233 - loss 0.59231490 - time (sec): 137.08 - samples/sec: 57.42 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 01:25:45,944 epoch 5 - iter 1107/1233 - loss 0.59249888 - time (sec): 154.11 - samples/sec: 57.47 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 01:26:02,986 epoch 5 - iter 1230/1233 - loss 0.59473729 - time (sec): 171.15 - samples/sec: 57.49 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 01:26:03,375 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:26:03,375 EPOCH 5 done: loss 0.5943 - lr: 0.000000\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:26:14,914 DEV : loss 0.6485000252723694 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]\n",
      "2024-11-10 01:26:26,615 TEST : loss 0.6485000252723694 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:26:29,321 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:26:29,322 Testing using last state of model ...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:11<00:00,  1.14it/s]\n",
      "2024-11-10 01:26:40,774 \n",
      "Results:\n",
      "- F-score (micro) 0.7938\n",
      "- F-score (macro) 0.295\n",
      "- Accuracy 0.7938\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ноутбук     0.7938    1.0000    0.8851       154\n",
      "      Сервер     0.0000    0.0000    0.0000        29\n",
      "         СХД     0.0000    0.0000    0.0000        11\n",
      "\n",
      "    accuracy                         0.7938       194\n",
      "   macro avg     0.2646    0.3333    0.2950       194\n",
      "weighted avg     0.6301    0.7938    0.7026       194\n",
      "\n",
      "2024-11-10 01:26:40,774 ----------------------------------------------------------------------------------------------------\n",
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.92it/s]\n",
      "2024/11/10 01:27:03 INFO mlflow.tracking._tracking_service.client: 🏃 View run inquisitive-colt-478 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/00fab0584aa647a0a70d0b6093ae2a35.\n",
      "2024/11/10 01:27:03 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 01:27:10,090 Reading data from datav2\n",
      "2024-11-10 01:27:10,090 Train: datav2/train.csv\n",
      "2024-11-10 01:27:10,090 Dev: datav2/dev.csv\n",
      "2024-11-10 01:27:10,090 Test: datav2/test.csv\n",
      "2024-11-10 01:27:10,140 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1755.22it/s]\n",
      "2024-11-10 01:27:15,762 Dictionary created for label 'label' with 3 values: Ноутбук (seen 8130 times), Сервер (seen 1075 times), СХД (seen 655 times)\n",
      "2024-11-10 01:27:17,195 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): DebertaModel(\n",
      "      (embeddings): DebertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50266, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): DebertaLayerNorm()\n",
      "        (dropout): StableDropout()\n",
      "      )\n",
      "      (encoder): DebertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x DebertaLayer(\n",
      "            (attention): DebertaAttention(\n",
      "              (self): DisentangledSelfAttention(\n",
      "                (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "              (output): DebertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): DebertaLayerNorm()\n",
      "                (dropout): StableDropout()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): DebertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): DebertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 01:27:17,196 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 01:27:17,196 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Train:  9860 sentences\n",
      "2024-11-10 01:27:17,196         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 01:27:17,196 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Training Params:\n",
      "2024-11-10 01:27:17,196  - learning_rate: \"5e-05\" \n",
      "2024-11-10 01:27:17,196  - mini_batch_size: \"8\"\n",
      "2024-11-10 01:27:17,196  - max_epochs: \"5\"\n",
      "2024-11-10 01:27:17,196  - shuffle: \"True\"\n",
      "2024-11-10 01:27:17,196 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,196 Plugins:\n",
      "2024-11-10 01:27:17,196  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,197 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 01:27:17,197  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,197 Computation:\n",
      "2024-11-10 01:27:17,197  - compute on device: cuda:0\n",
      "2024-11-10 01:27:17,197  - embedding storage: none\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,197 Model training base path: \"modelsv2/datav2/deepvk_USER_base\"\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:17,197 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:27:25,486 epoch 1 - iter 123/1233 - loss 0.32389420 - time (sec): 8.29 - samples/sec: 118.72 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:27:33,589 epoch 1 - iter 246/1233 - loss 0.16524380 - time (sec): 16.39 - samples/sec: 120.06 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:27:41,887 epoch 1 - iter 369/1233 - loss 0.11871837 - time (sec): 24.69 - samples/sec: 119.57 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:27:49,648 epoch 1 - iter 492/1233 - loss 0.09643388 - time (sec): 32.45 - samples/sec: 121.29 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:27:58,212 epoch 1 - iter 615/1233 - loss 0.08686119 - time (sec): 41.01 - samples/sec: 119.96 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 01:28:06,951 epoch 1 - iter 738/1233 - loss 0.07384475 - time (sec): 49.75 - samples/sec: 118.66 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 01:28:15,360 epoch 1 - iter 861/1233 - loss 0.07284237 - time (sec): 58.16 - samples/sec: 118.43 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 01:28:23,792 epoch 1 - iter 984/1233 - loss 0.06490788 - time (sec): 66.59 - samples/sec: 118.21 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 01:28:32,346 epoch 1 - iter 1107/1233 - loss 0.05911213 - time (sec): 75.15 - samples/sec: 117.85 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 01:28:39,564 epoch 1 - iter 1230/1233 - loss 0.05609780 - time (sec): 82.37 - samples/sec: 119.47 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 01:28:39,754 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:28:39,755 EPOCH 1 done: loss 0.0560 - lr: 0.000044\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.12it/s]\n",
      "2024-11-10 01:28:41,193 DEV : loss 0.12663452327251434 - f1-score (micro avg)  0.9794\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.03it/s]\n",
      "2024-11-10 01:28:43,068 TEST : loss 0.12663452327251434 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 01:28:43,262 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:28:51,055 epoch 2 - iter 123/1233 - loss 0.00859892 - time (sec): 7.79 - samples/sec: 126.27 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 01:28:59,564 epoch 2 - iter 246/1233 - loss 0.01579806 - time (sec): 16.30 - samples/sec: 120.73 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 01:29:08,128 epoch 2 - iter 369/1233 - loss 0.01053553 - time (sec): 24.87 - samples/sec: 118.72 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 01:29:16,678 epoch 2 - iter 492/1233 - loss 0.01251504 - time (sec): 33.42 - samples/sec: 117.79 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:29:25,195 epoch 2 - iter 615/1233 - loss 0.01659385 - time (sec): 41.93 - samples/sec: 117.33 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 01:29:33,590 epoch 2 - iter 738/1233 - loss 0.02661105 - time (sec): 50.33 - samples/sec: 117.31 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 01:29:41,917 epoch 2 - iter 861/1233 - loss 0.02789911 - time (sec): 58.65 - samples/sec: 117.43 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 01:29:49,700 epoch 2 - iter 984/1233 - loss 0.06339075 - time (sec): 66.44 - samples/sec: 118.49 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 01:29:57,757 epoch 2 - iter 1107/1233 - loss 0.07533164 - time (sec): 74.49 - samples/sec: 118.88 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 01:30:05,384 epoch 2 - iter 1230/1233 - loss 0.08408192 - time (sec): 82.12 - samples/sec: 119.82 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 01:30:05,552 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:30:05,552 EPOCH 2 done: loss 0.0842 - lr: 0.000033\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.26it/s]\n",
      "2024-11-10 01:30:06,968 DEV : loss 0.2243126928806305 - f1-score (micro avg)  0.9227\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.09it/s]\n",
      "2024-11-10 01:30:08,780 TEST : loss 0.2243126928806305 - f1-score (micro avg)  0.9227\n",
      "2024-11-10 01:30:08,974 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:30:15,951 epoch 3 - iter 123/1233 - loss 0.17272154 - time (sec): 6.98 - samples/sec: 141.05 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 01:30:24,172 epoch 3 - iter 246/1233 - loss 0.14596833 - time (sec): 15.20 - samples/sec: 129.50 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 01:30:31,723 epoch 3 - iter 369/1233 - loss 0.13985149 - time (sec): 22.75 - samples/sec: 129.77 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:30:40,056 epoch 3 - iter 492/1233 - loss 0.13880050 - time (sec): 31.08 - samples/sec: 126.64 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 01:30:47,368 epoch 3 - iter 615/1233 - loss 0.14689119 - time (sec): 38.39 - samples/sec: 128.15 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 01:30:54,996 epoch 3 - iter 738/1233 - loss 0.17159819 - time (sec): 46.02 - samples/sec: 128.29 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 01:31:03,379 epoch 3 - iter 861/1233 - loss 0.23225603 - time (sec): 54.40 - samples/sec: 126.61 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 01:31:11,966 epoch 3 - iter 984/1233 - loss 0.27469699 - time (sec): 62.99 - samples/sec: 124.97 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 01:31:20,475 epoch 3 - iter 1107/1233 - loss 0.31025357 - time (sec): 71.50 - samples/sec: 123.86 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 01:31:29,064 epoch 3 - iter 1230/1233 - loss 0.34056892 - time (sec): 80.09 - samples/sec: 122.86 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 01:31:29,268 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:31:29,269 EPOCH 3 done: loss 0.3405 - lr: 0.000022\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.13it/s]\n",
      "2024-11-10 01:31:30,880 DEV : loss 0.6929484009742737 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.26it/s]\n",
      "2024-11-10 01:31:32,490 TEST : loss 0.6929484009742737 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:31:32,697 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:31:41,424 epoch 4 - iter 123/1233 - loss 0.59128179 - time (sec): 8.73 - samples/sec: 112.76 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 01:31:49,811 epoch 4 - iter 246/1233 - loss 0.59624698 - time (sec): 17.11 - samples/sec: 115.00 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:31:58,240 epoch 4 - iter 369/1233 - loss 0.57837341 - time (sec): 25.54 - samples/sec: 115.57 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 01:32:06,931 epoch 4 - iter 492/1233 - loss 0.56980733 - time (sec): 34.23 - samples/sec: 114.98 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 01:32:15,347 epoch 4 - iter 615/1233 - loss 0.56779731 - time (sec): 42.65 - samples/sec: 115.36 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 01:32:22,610 epoch 4 - iter 738/1233 - loss 0.57474952 - time (sec): 49.91 - samples/sec: 118.29 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 01:32:29,523 epoch 4 - iter 861/1233 - loss 0.56484829 - time (sec): 56.83 - samples/sec: 121.21 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 01:32:36,514 epoch 4 - iter 984/1233 - loss 0.54675074 - time (sec): 63.82 - samples/sec: 123.36 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 01:32:44,025 epoch 4 - iter 1107/1233 - loss 0.51637023 - time (sec): 71.33 - samples/sec: 124.16 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 01:32:51,547 epoch 4 - iter 1230/1233 - loss 0.48358855 - time (sec): 78.85 - samples/sec: 124.80 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 01:32:51,710 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:32:51,710 EPOCH 4 done: loss 0.4832 - lr: 0.000011\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.19it/s]\n",
      "2024-11-10 01:32:53,138 DEV : loss 0.3298746645450592 - f1-score (micro avg)  0.8711\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.90it/s]\n",
      "2024-11-10 01:32:54,988 TEST : loss 0.3298746645450592 - f1-score (micro avg)  0.8711\n",
      "2024-11-10 01:32:55,189 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:33:03,127 epoch 5 - iter 123/1233 - loss 0.17361408 - time (sec): 7.94 - samples/sec: 123.97 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:33:11,385 epoch 5 - iter 246/1233 - loss 0.17112680 - time (sec): 16.20 - samples/sec: 121.52 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 01:33:18,301 epoch 5 - iter 369/1233 - loss 0.18408901 - time (sec): 23.11 - samples/sec: 127.73 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 01:33:25,556 epoch 5 - iter 492/1233 - loss 0.18536852 - time (sec): 30.37 - samples/sec: 129.62 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 01:33:33,267 epoch 5 - iter 615/1233 - loss 0.18364063 - time (sec): 38.08 - samples/sec: 129.21 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 01:33:40,922 epoch 5 - iter 738/1233 - loss 0.17840393 - time (sec): 45.73 - samples/sec: 129.10 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 01:33:49,349 epoch 5 - iter 861/1233 - loss 0.17844636 - time (sec): 54.16 - samples/sec: 127.18 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 01:33:57,940 epoch 5 - iter 984/1233 - loss 0.17893981 - time (sec): 62.75 - samples/sec: 125.45 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 01:34:06,439 epoch 5 - iter 1107/1233 - loss 0.17640476 - time (sec): 71.25 - samples/sec: 124.30 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 01:34:14,686 epoch 5 - iter 1230/1233 - loss 0.17741990 - time (sec): 79.50 - samples/sec: 123.78 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 01:34:14,890 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:14,890 EPOCH 5 done: loss 0.1773 - lr: 0.000000\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.91it/s]\n",
      "2024-11-10 01:34:16,547 DEV : loss 0.36851274967193604 - f1-score (micro avg)  0.8711\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.17it/s]\n",
      "2024-11-10 01:34:18,171 TEST : loss 0.36851274967193604 - f1-score (micro avg)  0.8711\n",
      "2024-11-10 01:34:19,138 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:19,139 Testing using last state of model ...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.07it/s]\n",
      "2024-11-10 01:34:20,761 \n",
      "Results:\n",
      "- F-score (micro) 0.8711\n",
      "- F-score (macro) 0.5504\n",
      "- Accuracy 0.8711\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ноутбук     1.0000    0.9091    0.9524       154\n",
      "      Сервер     0.5370    1.0000    0.6988        29\n",
      "         СХД     0.0000    0.0000    0.0000        11\n",
      "\n",
      "    accuracy                         0.8711       194\n",
      "   macro avg     0.5123    0.6364    0.5504       194\n",
      "weighted avg     0.8741    0.8711    0.8605       194\n",
      "\n",
      "2024-11-10 01:34:20,762 ----------------------------------------------------------------------------------------------------\n",
      "100%|███████████████████████████████████████████| 25/25 [00:01<00:00, 21.40it/s]\n",
      "2024/11/10 01:34:26 INFO mlflow.tracking._tracking_service.client: 🏃 View run dapper-sloth-973 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/bedb9a493d1d48ba9db7df74a1adbdc8.\n",
      "2024/11/10 01:34:26 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 01:34:32,886 Reading data from datav2\n",
      "2024-11-10 01:34:32,886 Train: datav2/train.csv\n",
      "2024-11-10 01:34:32,886 Dev: datav2/dev.csv\n",
      "2024-11-10 01:34:32,886 Test: datav2/test.csv\n",
      "2024-11-10 01:34:32,933 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1769.06it/s]\n",
      "2024-11-10 01:34:38,511 Dictionary created for label 'label' with 3 values: Ноутбук (seen 8130 times), Сервер (seen 1075 times), СХД (seen 655 times)\n",
      "2024-11-10 01:34:42,089 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(250003, 1024, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Train:  9860 sentences\n",
      "2024-11-10 01:34:42,091         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Training Params:\n",
      "2024-11-10 01:34:42,091  - learning_rate: \"5e-05\" \n",
      "2024-11-10 01:34:42,091  - mini_batch_size: \"8\"\n",
      "2024-11-10 01:34:42,091  - max_epochs: \"5\"\n",
      "2024-11-10 01:34:42,091  - shuffle: \"True\"\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Plugins:\n",
      "2024-11-10 01:34:42,091  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 01:34:42,091 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,091 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 01:34:42,091  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 01:34:42,092 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,092 Computation:\n",
      "2024-11-10 01:34:42,092  - compute on device: cuda:0\n",
      "2024-11-10 01:34:42,092  - embedding storage: none\n",
      "2024-11-10 01:34:42,092 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,092 Model training base path: \"modelsv2/datav2/intfloat_multilingual_e5_large_instruct\"\n",
      "2024-11-10 01:34:42,092 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:34:42,092 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:35:02,087 epoch 1 - iter 123/1233 - loss 0.28510497 - time (sec): 19.99 - samples/sec: 49.21 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:35:22,040 epoch 1 - iter 246/1233 - loss 0.15675579 - time (sec): 39.95 - samples/sec: 49.27 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:35:42,175 epoch 1 - iter 369/1233 - loss 0.10712950 - time (sec): 60.08 - samples/sec: 49.13 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:36:02,178 epoch 1 - iter 492/1233 - loss 0.09558776 - time (sec): 80.08 - samples/sec: 49.15 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:36:22,260 epoch 1 - iter 615/1233 - loss 0.08139954 - time (sec): 100.17 - samples/sec: 49.12 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 01:36:42,157 epoch 1 - iter 738/1233 - loss 0.07600239 - time (sec): 120.06 - samples/sec: 49.17 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 01:37:02,239 epoch 1 - iter 861/1233 - loss 0.09148924 - time (sec): 140.15 - samples/sec: 49.15 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 01:37:22,293 epoch 1 - iter 984/1233 - loss 0.08309864 - time (sec): 160.20 - samples/sec: 49.14 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 01:37:42,287 epoch 1 - iter 1107/1233 - loss 0.08057814 - time (sec): 180.19 - samples/sec: 49.15 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 01:38:02,245 epoch 1 - iter 1230/1233 - loss 0.08208214 - time (sec): 200.15 - samples/sec: 49.16 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 01:38:02,696 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:38:02,696 EPOCH 1 done: loss 0.0834 - lr: 0.000044\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.21it/s]\n",
      "2024-11-10 01:38:05,799 DEV : loss 1.3000657558441162 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.24it/s]\n",
      "2024-11-10 01:38:09,275 TEST : loss 1.3000657558441162 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:38:09,471 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:38:29,650 epoch 2 - iter 123/1233 - loss 0.75884688 - time (sec): 20.18 - samples/sec: 48.77 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 01:38:49,780 epoch 2 - iter 246/1233 - loss 0.70812750 - time (sec): 40.31 - samples/sec: 48.82 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 01:39:09,563 epoch 2 - iter 369/1233 - loss 0.69779509 - time (sec): 60.09 - samples/sec: 49.13 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 01:39:29,622 epoch 2 - iter 492/1233 - loss 0.67755514 - time (sec): 80.15 - samples/sec: 49.11 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:39:49,425 epoch 2 - iter 615/1233 - loss 0.66662362 - time (sec): 99.95 - samples/sec: 49.22 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 01:40:09,402 epoch 2 - iter 738/1233 - loss 0.65954769 - time (sec): 119.93 - samples/sec: 49.23 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 01:40:29,343 epoch 2 - iter 861/1233 - loss 0.65496456 - time (sec): 139.87 - samples/sec: 49.25 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 01:40:49,402 epoch 2 - iter 984/1233 - loss 0.64892974 - time (sec): 159.93 - samples/sec: 49.22 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 01:41:09,181 epoch 2 - iter 1107/1233 - loss 0.64029426 - time (sec): 179.71 - samples/sec: 49.28 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 01:41:28,961 epoch 2 - iter 1230/1233 - loss 0.63898031 - time (sec): 199.49 - samples/sec: 49.33 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 01:41:29,459 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:41:29,459 EPOCH 2 done: loss 0.6388 - lr: 0.000033\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.25it/s]\n",
      "2024-11-10 01:41:32,532 DEV : loss 0.6691238284111023 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.30it/s]\n",
      "2024-11-10 01:41:35,763 TEST : loss 0.6691238284111023 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:41:36,144 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:41:55,916 epoch 3 - iter 123/1233 - loss 0.66237909 - time (sec): 19.77 - samples/sec: 49.77 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 01:42:15,637 epoch 3 - iter 246/1233 - loss 0.62206798 - time (sec): 39.49 - samples/sec: 49.83 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 01:42:35,798 epoch 3 - iter 369/1233 - loss 0.62717145 - time (sec): 59.65 - samples/sec: 49.49 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:42:55,455 epoch 3 - iter 492/1233 - loss 0.61705122 - time (sec): 79.31 - samples/sec: 49.63 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 01:43:15,566 epoch 3 - iter 615/1233 - loss 0.61367134 - time (sec): 99.42 - samples/sec: 49.49 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 01:43:35,538 epoch 3 - iter 738/1233 - loss 0.61679914 - time (sec): 119.39 - samples/sec: 49.45 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 01:43:55,456 epoch 3 - iter 861/1233 - loss 0.60943082 - time (sec): 139.31 - samples/sec: 49.44 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 01:44:15,552 epoch 3 - iter 984/1233 - loss 0.60960876 - time (sec): 159.41 - samples/sec: 49.38 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 01:44:35,585 epoch 3 - iter 1107/1233 - loss 0.60743736 - time (sec): 179.44 - samples/sec: 49.35 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 01:44:55,746 epoch 3 - iter 1230/1233 - loss 0.60803533 - time (sec): 199.60 - samples/sec: 49.30 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 01:44:56,218 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:44:56,218 EPOCH 3 done: loss 0.6075 - lr: 0.000022\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.23it/s]\n",
      "2024-11-10 01:44:59,308 DEV : loss 0.652289628982544 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  3.97it/s]\n",
      "2024-11-10 01:45:02,809 TEST : loss 0.652289628982544 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:45:03,003 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:45:22,925 epoch 4 - iter 123/1233 - loss 0.64207490 - time (sec): 19.92 - samples/sec: 49.40 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 01:45:42,895 epoch 4 - iter 246/1233 - loss 0.61123030 - time (sec): 39.89 - samples/sec: 49.34 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:46:02,616 epoch 4 - iter 369/1233 - loss 0.60943512 - time (sec): 59.61 - samples/sec: 49.52 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 01:46:22,490 epoch 4 - iter 492/1233 - loss 0.60648189 - time (sec): 79.49 - samples/sec: 49.52 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 01:46:42,406 epoch 4 - iter 615/1233 - loss 0.59433764 - time (sec): 99.40 - samples/sec: 49.50 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 01:47:02,300 epoch 4 - iter 738/1233 - loss 0.60204630 - time (sec): 119.30 - samples/sec: 49.49 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 01:47:22,228 epoch 4 - iter 861/1233 - loss 0.59964816 - time (sec): 139.22 - samples/sec: 49.47 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 01:47:42,144 epoch 4 - iter 984/1233 - loss 0.60093547 - time (sec): 159.14 - samples/sec: 49.47 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 01:48:02,276 epoch 4 - iter 1107/1233 - loss 0.60113857 - time (sec): 179.27 - samples/sec: 49.40 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 01:48:22,260 epoch 4 - iter 1230/1233 - loss 0.59916310 - time (sec): 199.26 - samples/sec: 49.38 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 01:48:22,777 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:48:22,777 EPOCH 4 done: loss 0.5992 - lr: 0.000011\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.24it/s]\n",
      "2024-11-10 01:48:25,855 DEV : loss 0.6639564633369446 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.29it/s]\n",
      "2024-11-10 01:48:29,348 TEST : loss 0.6639564633369446 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:48:29,542 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:48:49,534 epoch 5 - iter 123/1233 - loss 0.59414472 - time (sec): 19.99 - samples/sec: 49.22 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:49:09,380 epoch 5 - iter 246/1233 - loss 0.59009342 - time (sec): 39.84 - samples/sec: 49.40 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 01:49:29,311 epoch 5 - iter 369/1233 - loss 0.60941239 - time (sec): 59.77 - samples/sec: 49.39 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 01:49:49,456 epoch 5 - iter 492/1233 - loss 0.59440069 - time (sec): 79.91 - samples/sec: 49.25 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 01:50:09,223 epoch 5 - iter 615/1233 - loss 0.59836967 - time (sec): 99.68 - samples/sec: 49.36 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 01:50:29,192 epoch 5 - iter 738/1233 - loss 0.60172556 - time (sec): 119.65 - samples/sec: 49.34 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 01:50:49,041 epoch 5 - iter 861/1233 - loss 0.59904770 - time (sec): 139.50 - samples/sec: 49.38 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 01:51:09,024 epoch 5 - iter 984/1233 - loss 0.60068875 - time (sec): 159.48 - samples/sec: 49.36 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 01:51:28,993 epoch 5 - iter 1107/1233 - loss 0.59725396 - time (sec): 179.45 - samples/sec: 49.35 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 01:51:48,752 epoch 5 - iter 1230/1233 - loss 0.60019637 - time (sec): 199.21 - samples/sec: 49.40 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 01:51:49,369 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:51:49,369 EPOCH 5 done: loss 0.5993 - lr: 0.000000\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.26it/s]\n",
      "2024-11-10 01:51:52,435 DEV : loss 0.6652141809463501 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.31it/s]\n",
      "2024-11-10 01:51:55,660 TEST : loss 0.6652141809463501 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:51:59,151 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:51:59,153 Testing using last state of model ...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:02<00:00,  4.34it/s]\n",
      "2024-11-10 01:52:02,159 \n",
      "Results:\n",
      "- F-score (micro) 0.7938\n",
      "- F-score (macro) 0.295\n",
      "- Accuracy 0.7938\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ноутбук     0.7938    1.0000    0.8851       154\n",
      "      Сервер     0.0000    0.0000    0.0000        29\n",
      "         СХД     0.0000    0.0000    0.0000        11\n",
      "\n",
      "    accuracy                         0.7938       194\n",
      "   macro avg     0.2646    0.3333    0.2950       194\n",
      "weighted avg     0.6301    0.7938    0.7026       194\n",
      "\n",
      "2024-11-10 01:52:02,159 ----------------------------------------------------------------------------------------------------\n",
      "100%|███████████████████████████████████████████| 25/25 [00:02<00:00, 10.00it/s]\n",
      "2024/11/10 01:52:25 INFO mlflow.tracking._tracking_service.client: 🏃 View run glamorous-hog-70 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/dceea6d5bc694f58bef4fae0ba5e436c.\n",
      "2024/11/10 01:52:25 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 01:52:31,988 Reading data from datav2\n",
      "2024-11-10 01:52:31,988 Train: datav2/train.csv\n",
      "2024-11-10 01:52:31,988 Dev: datav2/dev.csv\n",
      "2024-11-10 01:52:31,988 Test: datav2/test.csv\n",
      "2024-11-10 01:52:32,035 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1721.64it/s]\n",
      "2024-11-10 01:52:37,766 Dictionary created for label 'label' with 3 values: Ноутбук (seen 8130 times), Сервер (seen 1075 times), СХД (seen 655 times)\n",
      "2024-11-10 01:52:42,002 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,003 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(250003, 1024, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 01:52:42,003 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Train:  9860 sentences\n",
      "2024-11-10 01:52:42,004         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Training Params:\n",
      "2024-11-10 01:52:42,004  - learning_rate: \"5e-05\" \n",
      "2024-11-10 01:52:42,004  - mini_batch_size: \"8\"\n",
      "2024-11-10 01:52:42,004  - max_epochs: \"5\"\n",
      "2024-11-10 01:52:42,004  - shuffle: \"True\"\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Plugins:\n",
      "2024-11-10 01:52:42,004  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 01:52:42,004  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Computation:\n",
      "2024-11-10 01:52:42,004  - compute on device: cuda:0\n",
      "2024-11-10 01:52:42,004  - embedding storage: none\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 Model training base path: \"modelsv2/datav2/intfloat_multilingual_e5_large\"\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:52:42,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:53:02,111 epoch 1 - iter 123/1233 - loss 0.33014339 - time (sec): 20.11 - samples/sec: 48.94 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 01:53:22,121 epoch 1 - iter 246/1233 - loss 0.17216167 - time (sec): 40.12 - samples/sec: 49.06 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 01:53:42,332 epoch 1 - iter 369/1233 - loss 0.11551793 - time (sec): 60.33 - samples/sec: 48.93 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 01:54:02,335 epoch 1 - iter 492/1233 - loss 0.09169493 - time (sec): 80.33 - samples/sec: 49.00 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:54:22,580 epoch 1 - iter 615/1233 - loss 0.07691794 - time (sec): 100.57 - samples/sec: 48.92 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 01:54:42,588 epoch 1 - iter 738/1233 - loss 0.06875369 - time (sec): 120.58 - samples/sec: 48.96 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 01:55:02,597 epoch 1 - iter 861/1233 - loss 0.06580578 - time (sec): 140.59 - samples/sec: 48.99 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 01:55:22,511 epoch 1 - iter 984/1233 - loss 0.05841207 - time (sec): 160.50 - samples/sec: 49.05 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 01:55:42,183 epoch 1 - iter 1107/1233 - loss 0.05192281 - time (sec): 180.18 - samples/sec: 49.15 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 01:56:02,414 epoch 1 - iter 1230/1233 - loss 0.05170570 - time (sec): 200.41 - samples/sec: 49.10 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 01:56:02,891 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:56:02,891 EPOCH 1 done: loss 0.0516 - lr: 0.000044\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.21it/s]\n",
      "2024-11-10 01:56:05,994 DEV : loss 0.22302745282649994 - f1-score (micro avg)  0.9845\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.03it/s]\n",
      "2024-11-10 01:56:09,426 TEST : loss 0.22302745282649994 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 01:56:09,622 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:56:29,355 epoch 2 - iter 123/1233 - loss 0.07942303 - time (sec): 19.73 - samples/sec: 49.87 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 01:56:49,440 epoch 2 - iter 246/1233 - loss 0.30398308 - time (sec): 39.82 - samples/sec: 49.43 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 01:57:09,234 epoch 2 - iter 369/1233 - loss 0.41364645 - time (sec): 59.61 - samples/sec: 49.52 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 01:57:29,207 epoch 2 - iter 492/1233 - loss 0.46812341 - time (sec): 79.58 - samples/sec: 49.46 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 01:57:49,255 epoch 2 - iter 615/1233 - loss 0.50203010 - time (sec): 99.63 - samples/sec: 49.38 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 01:58:09,601 epoch 2 - iter 738/1233 - loss 0.52549165 - time (sec): 119.98 - samples/sec: 49.21 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 01:58:29,547 epoch 2 - iter 861/1233 - loss 0.53410362 - time (sec): 139.92 - samples/sec: 49.23 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 01:58:49,921 epoch 2 - iter 984/1233 - loss 0.54526580 - time (sec): 160.30 - samples/sec: 49.11 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 01:59:10,183 epoch 2 - iter 1107/1233 - loss 0.55369879 - time (sec): 180.56 - samples/sec: 49.05 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 01:59:30,189 epoch 2 - iter 1230/1233 - loss 0.56993106 - time (sec): 200.57 - samples/sec: 49.06 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 01:59:30,678 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:59:30,679 EPOCH 2 done: loss 0.5699 - lr: 0.000033\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  3.96it/s]\n",
      "2024-11-10 01:59:33,973 DEV : loss 0.6741207838058472 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.25it/s]\n",
      "2024-11-10 01:59:37,259 TEST : loss 0.6741207838058472 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 01:59:37,463 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 01:59:57,474 epoch 3 - iter 123/1233 - loss 0.55449453 - time (sec): 20.01 - samples/sec: 49.18 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 02:00:17,553 epoch 3 - iter 246/1233 - loss 0.60498484 - time (sec): 40.09 - samples/sec: 49.09 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 02:00:37,866 epoch 3 - iter 369/1233 - loss 0.61595911 - time (sec): 60.40 - samples/sec: 48.87 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:00:58,026 epoch 3 - iter 492/1233 - loss 0.60760268 - time (sec): 80.56 - samples/sec: 48.86 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 02:01:18,240 epoch 3 - iter 615/1233 - loss 0.60903325 - time (sec): 100.78 - samples/sec: 48.82 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 02:01:38,271 epoch 3 - iter 738/1233 - loss 0.61385080 - time (sec): 120.81 - samples/sec: 48.87 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 02:01:58,229 epoch 3 - iter 861/1233 - loss 0.60862794 - time (sec): 140.77 - samples/sec: 48.93 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 02:02:18,326 epoch 3 - iter 984/1233 - loss 0.60867641 - time (sec): 160.86 - samples/sec: 48.94 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 02:02:38,257 epoch 3 - iter 1107/1233 - loss 0.60773768 - time (sec): 180.79 - samples/sec: 48.98 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 02:02:58,340 epoch 3 - iter 1230/1233 - loss 0.60937208 - time (sec): 200.88 - samples/sec: 48.99 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 02:02:58,782 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:02:58,782 EPOCH 3 done: loss 0.6096 - lr: 0.000022\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.23it/s]\n",
      "2024-11-10 02:03:01,870 DEV : loss 0.6529877185821533 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  3.98it/s]\n",
      "2024-11-10 02:03:05,344 TEST : loss 0.6529877185821533 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 02:03:05,582 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:03:25,697 epoch 4 - iter 123/1233 - loss 0.59127931 - time (sec): 20.11 - samples/sec: 48.92 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 02:03:45,824 epoch 4 - iter 246/1233 - loss 0.59136713 - time (sec): 40.24 - samples/sec: 48.91 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:04:06,077 epoch 4 - iter 369/1233 - loss 0.60359598 - time (sec): 60.49 - samples/sec: 48.80 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 02:04:26,167 epoch 4 - iter 492/1233 - loss 0.59508500 - time (sec): 80.58 - samples/sec: 48.84 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 02:04:46,154 epoch 4 - iter 615/1233 - loss 0.59910008 - time (sec): 100.57 - samples/sec: 48.92 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 02:05:06,284 epoch 4 - iter 738/1233 - loss 0.59841284 - time (sec): 120.70 - samples/sec: 48.91 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 02:05:26,613 epoch 4 - iter 861/1233 - loss 0.59787033 - time (sec): 141.03 - samples/sec: 48.84 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 02:05:46,489 epoch 4 - iter 984/1233 - loss 0.60111861 - time (sec): 160.90 - samples/sec: 48.92 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 02:06:06,653 epoch 4 - iter 1107/1233 - loss 0.60357341 - time (sec): 181.07 - samples/sec: 48.91 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 02:06:26,462 epoch 4 - iter 1230/1233 - loss 0.60532947 - time (sec): 200.88 - samples/sec: 48.98 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 02:06:26,955 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:06:26,955 EPOCH 4 done: loss 0.6048 - lr: 0.000011\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.22it/s]\n",
      "2024-11-10 02:06:30,046 DEV : loss 0.6393814086914062 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.26it/s]\n",
      "2024-11-10 02:06:33,480 TEST : loss 0.6393814086914062 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 02:06:33,679 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:06:53,746 epoch 5 - iter 123/1233 - loss 0.57926584 - time (sec): 20.06 - samples/sec: 49.04 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:07:13,875 epoch 5 - iter 246/1233 - loss 0.60402421 - time (sec): 40.19 - samples/sec: 48.96 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 02:07:33,826 epoch 5 - iter 369/1233 - loss 0.60360014 - time (sec): 60.15 - samples/sec: 49.08 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 02:07:54,015 epoch 5 - iter 492/1233 - loss 0.60284069 - time (sec): 80.33 - samples/sec: 49.00 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 02:08:14,033 epoch 5 - iter 615/1233 - loss 0.59736392 - time (sec): 100.35 - samples/sec: 49.03 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 02:08:34,061 epoch 5 - iter 738/1233 - loss 0.60246230 - time (sec): 120.38 - samples/sec: 49.04 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 02:08:53,930 epoch 5 - iter 861/1233 - loss 0.59912674 - time (sec): 140.25 - samples/sec: 49.11 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 02:09:14,082 epoch 5 - iter 984/1233 - loss 0.59870965 - time (sec): 160.40 - samples/sec: 49.08 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 02:09:33,917 epoch 5 - iter 1107/1233 - loss 0.59597039 - time (sec): 180.24 - samples/sec: 49.14 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 02:09:53,954 epoch 5 - iter 1230/1233 - loss 0.59671134 - time (sec): 200.27 - samples/sec: 49.13 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 02:09:54,423 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:09:54,423 EPOCH 5 done: loss 0.5964 - lr: 0.000000\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  3.98it/s]\n",
      "2024-11-10 02:09:57,704 DEV : loss 0.6447110772132874 - f1-score (micro avg)  0.7938\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.29it/s]\n",
      "2024-11-10 02:10:00,944 TEST : loss 0.6447110772132874 - f1-score (micro avg)  0.7938\n",
      "2024-11-10 02:10:04,531 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:04,533 Testing using last state of model ...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.05it/s]\n",
      "2024-11-10 02:10:07,758 \n",
      "Results:\n",
      "- F-score (micro) 0.7938\n",
      "- F-score (macro) 0.295\n",
      "- Accuracy 0.7938\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ноутбук     0.7938    1.0000    0.8851       154\n",
      "      Сервер     0.0000    0.0000    0.0000        29\n",
      "         СХД     0.0000    0.0000    0.0000        11\n",
      "\n",
      "    accuracy                         0.7938       194\n",
      "   macro avg     0.2646    0.3333    0.2950       194\n",
      "weighted avg     0.6301    0.7938    0.7026       194\n",
      "\n",
      "2024-11-10 02:10:07,758 ----------------------------------------------------------------------------------------------------\n",
      "100%|███████████████████████████████████████████| 25/25 [00:02<00:00,  9.97it/s]\n",
      "2024/11/10 02:10:31 INFO mlflow.tracking._tracking_service.client: 🏃 View run orderly-panda-894 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/cd55e610328946b48f2b6b7408e54387.\n",
      "2024/11/10 02:10:31 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 02:10:38,152 Reading data from datav2\n",
      "2024-11-10 02:10:38,152 Train: datav2/train.csv\n",
      "2024-11-10 02:10:38,152 Dev: datav2/dev.csv\n",
      "2024-11-10 02:10:38,152 Test: datav2/test.csv\n",
      "2024-11-10 02:10:38,199 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1769.80it/s]\n",
      "2024-11-10 02:10:43,775 Dictionary created for label 'label' with 3 values: Ноутбук (seen 8130 times), Сервер (seen 1075 times), СХД (seen 655 times)\n",
      "2024-11-10 02:10:46,389 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(250003, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 02:10:46,390 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 02:10:46,390 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Train:  9860 sentences\n",
      "2024-11-10 02:10:46,390         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 02:10:46,390 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Training Params:\n",
      "2024-11-10 02:10:46,390  - learning_rate: \"5e-05\" \n",
      "2024-11-10 02:10:46,390  - mini_batch_size: \"8\"\n",
      "2024-11-10 02:10:46,390  - max_epochs: \"5\"\n",
      "2024-11-10 02:10:46,390  - shuffle: \"True\"\n",
      "2024-11-10 02:10:46,390 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,390 Plugins:\n",
      "2024-11-10 02:10:46,391  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,391 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 02:10:46,391  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,391 Computation:\n",
      "2024-11-10 02:10:46,391  - compute on device: cuda:0\n",
      "2024-11-10 02:10:46,391  - embedding storage: none\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,391 Model training base path: \"modelsv2/datav2/sentence_transformers_paraphrase_multilingual_mpnet_base_v2\"\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:46,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:10:55,005 epoch 1 - iter 123/1233 - loss 0.39104016 - time (sec): 8.61 - samples/sec: 114.24 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:11:03,235 epoch 1 - iter 246/1233 - loss 0.20077234 - time (sec): 16.84 - samples/sec: 116.84 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:11:11,542 epoch 1 - iter 369/1233 - loss 0.13406119 - time (sec): 25.15 - samples/sec: 117.37 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:11:20,073 epoch 1 - iter 492/1233 - loss 0.10560384 - time (sec): 33.68 - samples/sec: 116.86 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:11:28,035 epoch 1 - iter 615/1233 - loss 0.08664562 - time (sec): 41.64 - samples/sec: 118.15 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 02:11:36,180 epoch 1 - iter 738/1233 - loss 0.07441882 - time (sec): 49.79 - samples/sec: 118.58 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 02:11:44,585 epoch 1 - iter 861/1233 - loss 0.06426602 - time (sec): 58.19 - samples/sec: 118.36 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 02:11:52,704 epoch 1 - iter 984/1233 - loss 0.06164236 - time (sec): 66.31 - samples/sec: 118.71 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 02:12:00,770 epoch 1 - iter 1107/1233 - loss 0.05759510 - time (sec): 74.38 - samples/sec: 119.07 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 02:12:09,204 epoch 1 - iter 1230/1233 - loss 0.05395360 - time (sec): 82.81 - samples/sec: 118.82 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 02:12:09,413 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:12:09,413 EPOCH 1 done: loss 0.0538 - lr: 0.000044\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 10.75it/s]\n",
      "2024-11-10 02:12:10,637 DEV : loss 0.13859358429908752 - f1-score (micro avg)  0.9845\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.05it/s]\n",
      "2024-11-10 02:12:12,294 TEST : loss 0.13859358429908752 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:12:12,497 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:12:20,746 epoch 2 - iter 123/1233 - loss 0.00115031 - time (sec): 8.25 - samples/sec: 119.30 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 02:12:29,127 epoch 2 - iter 246/1233 - loss 0.01642727 - time (sec): 16.63 - samples/sec: 118.35 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 02:12:37,144 epoch 2 - iter 369/1233 - loss 0.01147204 - time (sec): 24.65 - samples/sec: 119.78 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 02:12:45,420 epoch 2 - iter 492/1233 - loss 0.00936473 - time (sec): 32.92 - samples/sec: 119.56 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:12:53,831 epoch 2 - iter 615/1233 - loss 0.00979342 - time (sec): 41.33 - samples/sec: 119.04 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 02:13:02,102 epoch 2 - iter 738/1233 - loss 0.00817568 - time (sec): 49.60 - samples/sec: 119.02 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 02:13:10,334 epoch 2 - iter 861/1233 - loss 0.00701287 - time (sec): 57.84 - samples/sec: 119.10 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 02:13:18,873 epoch 2 - iter 984/1233 - loss 0.01006569 - time (sec): 66.38 - samples/sec: 118.60 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 02:13:26,944 epoch 2 - iter 1107/1233 - loss 0.00896203 - time (sec): 74.45 - samples/sec: 118.96 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 02:13:35,183 epoch 2 - iter 1230/1233 - loss 0.00910660 - time (sec): 82.68 - samples/sec: 119.01 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 02:13:35,393 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:13:35,393 EPOCH 2 done: loss 0.0091 - lr: 0.000033\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.59it/s]\n",
      "2024-11-10 02:13:36,761 DEV : loss 0.11494137346744537 - f1-score (micro avg)  0.9845\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 11.26it/s]\n",
      "2024-11-10 02:13:38,120 TEST : loss 0.11494137346744537 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:13:38,314 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:13:46,709 epoch 3 - iter 123/1233 - loss 0.00005706 - time (sec): 8.39 - samples/sec: 117.22 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 02:13:54,516 epoch 3 - iter 246/1233 - loss 0.00466487 - time (sec): 16.20 - samples/sec: 121.47 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 02:14:02,381 epoch 3 - iter 369/1233 - loss 0.00313352 - time (sec): 24.07 - samples/sec: 122.66 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:14:10,544 epoch 3 - iter 492/1233 - loss 0.00236744 - time (sec): 32.23 - samples/sec: 122.12 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 02:14:18,646 epoch 3 - iter 615/1233 - loss 0.00380301 - time (sec): 40.33 - samples/sec: 121.99 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 02:14:26,786 epoch 3 - iter 738/1233 - loss 0.00317588 - time (sec): 48.47 - samples/sec: 121.80 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 02:14:35,121 epoch 3 - iter 861/1233 - loss 0.00426605 - time (sec): 56.81 - samples/sec: 121.25 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 02:14:43,170 epoch 3 - iter 984/1233 - loss 0.00422201 - time (sec): 64.85 - samples/sec: 121.38 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 02:14:51,334 epoch 3 - iter 1107/1233 - loss 0.00375608 - time (sec): 73.02 - samples/sec: 121.28 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 02:14:59,735 epoch 3 - iter 1230/1233 - loss 0.00338310 - time (sec): 81.42 - samples/sec: 120.85 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 02:14:59,919 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:14:59,919 EPOCH 3 done: loss 0.0034 - lr: 0.000022\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 11.08it/s]\n",
      "2024-11-10 02:15:01,105 DEV : loss 0.11303524672985077 - f1-score (micro avg)  0.9897\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.29it/s]\n",
      "2024-11-10 02:15:02,709 TEST : loss 0.11303524672985077 - f1-score (micro avg)  0.9897\n",
      "2024-11-10 02:15:02,902 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:15:11,163 epoch 4 - iter 123/1233 - loss 0.01922881 - time (sec): 8.26 - samples/sec: 119.14 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 02:15:19,807 epoch 4 - iter 246/1233 - loss 0.00964056 - time (sec): 16.90 - samples/sec: 116.42 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:15:27,970 epoch 4 - iter 369/1233 - loss 0.00901600 - time (sec): 25.07 - samples/sec: 117.77 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 02:15:36,016 epoch 4 - iter 492/1233 - loss 0.00678014 - time (sec): 33.11 - samples/sec: 118.87 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 02:15:44,379 epoch 4 - iter 615/1233 - loss 0.00546578 - time (sec): 41.48 - samples/sec: 118.62 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 02:15:52,206 epoch 4 - iter 738/1233 - loss 0.00457149 - time (sec): 49.30 - samples/sec: 119.75 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 02:16:00,297 epoch 4 - iter 861/1233 - loss 0.00392216 - time (sec): 57.39 - samples/sec: 120.01 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 02:16:08,748 epoch 4 - iter 984/1233 - loss 0.00347694 - time (sec): 65.85 - samples/sec: 119.55 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 02:16:17,047 epoch 4 - iter 1107/1233 - loss 0.00310812 - time (sec): 74.14 - samples/sec: 119.44 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 02:16:25,390 epoch 4 - iter 1230/1233 - loss 0.00330267 - time (sec): 82.49 - samples/sec: 119.29 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 02:16:25,588 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:16:25,588 EPOCH 4 done: loss 0.0033 - lr: 0.000011\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.14it/s]\n",
      "2024-11-10 02:16:27,023 DEV : loss 0.14037089049816132 - f1-score (micro avg)  0.9845\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 11.15it/s]\n",
      "2024-11-10 02:16:28,396 TEST : loss 0.14037089049816132 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:16:28,589 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:16:36,942 epoch 5 - iter 123/1233 - loss 0.00002140 - time (sec): 8.35 - samples/sec: 117.81 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:16:45,215 epoch 5 - iter 246/1233 - loss 0.00002136 - time (sec): 16.63 - samples/sec: 118.38 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 02:16:53,457 epoch 5 - iter 369/1233 - loss 0.00002103 - time (sec): 24.87 - samples/sec: 118.71 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 02:17:01,929 epoch 5 - iter 492/1233 - loss 0.00002070 - time (sec): 33.34 - samples/sec: 118.06 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 02:17:10,170 epoch 5 - iter 615/1233 - loss 0.00002051 - time (sec): 41.58 - samples/sec: 118.32 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 02:17:18,516 epoch 5 - iter 738/1233 - loss 0.00143747 - time (sec): 49.93 - samples/sec: 118.26 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 02:17:27,095 epoch 5 - iter 861/1233 - loss 0.00256953 - time (sec): 58.50 - samples/sec: 117.73 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 02:17:35,437 epoch 5 - iter 984/1233 - loss 0.00225090 - time (sec): 66.85 - samples/sec: 117.76 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 02:17:43,796 epoch 5 - iter 1107/1233 - loss 0.00200309 - time (sec): 75.21 - samples/sec: 117.76 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 02:17:52,006 epoch 5 - iter 1230/1233 - loss 0.00180493 - time (sec): 83.42 - samples/sec: 117.96 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 02:17:52,203 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:17:52,203 EPOCH 5 done: loss 0.0018 - lr: 0.000000\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 11.19it/s]\n",
      "2024-11-10 02:17:53,378 DEV : loss 0.14704376459121704 - f1-score (micro avg)  0.9845\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.47it/s]\n",
      "2024-11-10 02:17:54,962 TEST : loss 0.14704376459121704 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:17:56,985 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:17:56,986 Testing using last state of model ...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 11.22it/s]\n",
      "2024-11-10 02:17:58,156 \n",
      "Results:\n",
      "- F-score (micro) 0.9845\n",
      "- F-score (macro) 0.953\n",
      "- Accuracy 0.9845\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ноутбук     0.9935    1.0000    0.9968       154\n",
      "      Сервер     1.0000    0.8966    0.9455        29\n",
      "         СХД     0.8462    1.0000    0.9167        11\n",
      "\n",
      "    accuracy                         0.9845       194\n",
      "   macro avg     0.9466    0.9655    0.9530       194\n",
      "weighted avg     0.9862    0.9845    0.9846       194\n",
      "\n",
      "2024-11-10 02:17:58,156 ----------------------------------------------------------------------------------------------------\n",
      "100%|███████████████████████████████████████████| 25/25 [00:01<00:00, 24.61it/s]\n",
      "2024/11/10 02:18:10 INFO mlflow.tracking._tracking_service.client: 🏃 View run popular-shad-817 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/9c7429bbe4124fda8de3aebd2e6d15d3.\n",
      "2024/11/10 02:18:10 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 02:18:17,014 Reading data from datav2\n",
      "2024-11-10 02:18:17,014 Train: datav2/train.csv\n",
      "2024-11-10 02:18:17,014 Dev: datav2/dev.csv\n",
      "2024-11-10 02:18:17,014 Test: datav2/test.csv\n",
      "2024-11-10 02:18:17,096 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1761.55it/s]\n",
      "2024-11-10 02:18:22,698 Dictionary created for label 'label' with 3 values: Ноутбук (seen 8130 times), Сервер (seen 1075 times), СХД (seen 655 times)\n",
      "2024-11-10 02:18:25,315 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,316 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): XLMRobertaModel(\n",
      "      (embeddings): XLMRobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(250003, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): XLMRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x XLMRobertaLayer(\n",
      "            (attention): XLMRobertaAttention(\n",
      "              (self): XLMRobertaSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): XLMRobertaSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): XLMRobertaIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): XLMRobertaOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): XLMRobertaPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 02:18:25,316 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,316 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 02:18:25,316 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,316 Train:  9860 sentences\n",
      "2024-11-10 02:18:25,316         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 02:18:25,316 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,316 Training Params:\n",
      "2024-11-10 02:18:25,316  - learning_rate: \"5e-05\" \n",
      "2024-11-10 02:18:25,317  - mini_batch_size: \"8\"\n",
      "2024-11-10 02:18:25,317  - max_epochs: \"5\"\n",
      "2024-11-10 02:18:25,317  - shuffle: \"True\"\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 Plugins:\n",
      "2024-11-10 02:18:25,317  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 02:18:25,317  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 Computation:\n",
      "2024-11-10 02:18:25,317  - compute on device: cuda:0\n",
      "2024-11-10 02:18:25,317  - embedding storage: none\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 Model training base path: \"modelsv2/datav2/intfloat_multilingual_e5_base\"\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:25,317 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:18:33,560 epoch 1 - iter 123/1233 - loss 0.42792191 - time (sec): 8.24 - samples/sec: 119.38 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:18:41,443 epoch 1 - iter 246/1233 - loss 0.22592079 - time (sec): 16.12 - samples/sec: 122.05 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:18:49,551 epoch 1 - iter 369/1233 - loss 0.15647078 - time (sec): 24.23 - samples/sec: 121.82 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:18:57,437 epoch 1 - iter 492/1233 - loss 0.11839237 - time (sec): 32.12 - samples/sec: 122.54 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:19:05,274 epoch 1 - iter 615/1233 - loss 0.09479429 - time (sec): 39.96 - samples/sec: 123.14 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 02:19:13,385 epoch 1 - iter 738/1233 - loss 0.08040311 - time (sec): 48.07 - samples/sec: 122.83 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 02:19:21,170 epoch 1 - iter 861/1233 - loss 0.07144028 - time (sec): 55.85 - samples/sec: 123.32 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 02:19:29,001 epoch 1 - iter 984/1233 - loss 0.06277958 - time (sec): 63.68 - samples/sec: 123.61 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 02:19:36,990 epoch 1 - iter 1107/1233 - loss 0.05622661 - time (sec): 71.67 - samples/sec: 123.56 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 02:19:45,171 epoch 1 - iter 1230/1233 - loss 0.05067951 - time (sec): 79.85 - samples/sec: 123.23 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 02:19:45,376 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:19:45,377 EPOCH 1 done: loss 0.0506 - lr: 0.000044\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 10.80it/s]\n",
      "2024-11-10 02:19:46,597 DEV : loss 0.22020356357097626 - f1-score (micro avg)  0.9845\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.18it/s]\n",
      "2024-11-10 02:19:48,233 TEST : loss 0.22020356357097626 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:19:48,452 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:19:56,512 epoch 2 - iter 123/1233 - loss 0.00000144 - time (sec): 8.06 - samples/sec: 122.09 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 02:20:04,887 epoch 2 - iter 246/1233 - loss 0.00453423 - time (sec): 16.43 - samples/sec: 119.75 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 02:20:13,053 epoch 2 - iter 369/1233 - loss 0.00302313 - time (sec): 24.60 - samples/sec: 120.00 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 02:20:21,299 epoch 2 - iter 492/1233 - loss 0.00254611 - time (sec): 32.85 - samples/sec: 119.83 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:20:29,378 epoch 2 - iter 615/1233 - loss 0.00760857 - time (sec): 40.93 - samples/sec: 120.22 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 02:20:37,680 epoch 2 - iter 738/1233 - loss 0.01080632 - time (sec): 49.23 - samples/sec: 119.93 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 02:20:45,936 epoch 2 - iter 861/1233 - loss 0.01019677 - time (sec): 57.48 - samples/sec: 119.83 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 02:20:54,417 epoch 2 - iter 984/1233 - loss 0.00928950 - time (sec): 65.96 - samples/sec: 119.34 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 02:21:02,776 epoch 2 - iter 1107/1233 - loss 0.00826100 - time (sec): 74.32 - samples/sec: 119.16 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 02:21:11,158 epoch 2 - iter 1230/1233 - loss 0.01016852 - time (sec): 82.71 - samples/sec: 118.98 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 02:21:11,361 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:21:11,361 EPOCH 2 done: loss 0.0104 - lr: 0.000033\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.68it/s]\n",
      "2024-11-10 02:21:12,716 DEV : loss 0.3316602408885956 - f1-score (micro avg)  0.9639\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 10.87it/s]\n",
      "2024-11-10 02:21:14,120 TEST : loss 0.3316602408885956 - f1-score (micro avg)  0.9639\n",
      "2024-11-10 02:21:14,504 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:21:22,803 epoch 3 - iter 123/1233 - loss 0.00004842 - time (sec): 8.30 - samples/sec: 118.57 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 02:21:30,868 epoch 3 - iter 246/1233 - loss 0.00002449 - time (sec): 16.36 - samples/sec: 120.27 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 02:21:39,214 epoch 3 - iter 369/1233 - loss 0.00001680 - time (sec): 24.71 - samples/sec: 119.47 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:21:47,728 epoch 3 - iter 492/1233 - loss 0.00005719 - time (sec): 33.22 - samples/sec: 118.47 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 02:21:56,144 epoch 3 - iter 615/1233 - loss 0.00004627 - time (sec): 41.64 - samples/sec: 118.16 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 02:22:04,683 epoch 3 - iter 738/1233 - loss 0.00003863 - time (sec): 50.18 - samples/sec: 117.66 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 02:22:13,020 epoch 3 - iter 861/1233 - loss 0.00014664 - time (sec): 58.52 - samples/sec: 117.71 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 02:22:21,352 epoch 3 - iter 984/1233 - loss 0.00271622 - time (sec): 66.85 - samples/sec: 117.76 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 02:22:29,834 epoch 3 - iter 1107/1233 - loss 0.00300286 - time (sec): 75.33 - samples/sec: 117.56 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 02:22:38,036 epoch 3 - iter 1230/1233 - loss 0.00284235 - time (sec): 83.53 - samples/sec: 117.80 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 02:22:38,234 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:22:38,234 EPOCH 3 done: loss 0.0028 - lr: 0.000022\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 11.09it/s]\n",
      "2024-11-10 02:22:39,419 DEV : loss 0.2938547432422638 - f1-score (micro avg)  0.9794\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.02it/s]\n",
      "2024-11-10 02:22:41,082 TEST : loss 0.2938547432422638 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:22:41,290 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:22:49,425 epoch 4 - iter 123/1233 - loss 0.00000100 - time (sec): 8.13 - samples/sec: 120.97 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 02:22:57,851 epoch 4 - iter 246/1233 - loss 0.00000124 - time (sec): 16.56 - samples/sec: 118.84 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:23:05,732 epoch 4 - iter 369/1233 - loss 0.00000105 - time (sec): 24.44 - samples/sec: 120.78 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 02:23:13,899 epoch 4 - iter 492/1233 - loss 0.00000092 - time (sec): 32.61 - samples/sec: 120.71 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 02:23:22,456 epoch 4 - iter 615/1233 - loss 0.00000082 - time (sec): 41.17 - samples/sec: 119.52 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 02:23:30,816 epoch 4 - iter 738/1233 - loss 0.00000075 - time (sec): 49.53 - samples/sec: 119.21 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 02:23:39,112 epoch 4 - iter 861/1233 - loss 0.00177730 - time (sec): 57.82 - samples/sec: 119.13 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 02:23:47,348 epoch 4 - iter 984/1233 - loss 0.00179145 - time (sec): 66.06 - samples/sec: 119.17 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 02:23:55,552 epoch 4 - iter 1107/1233 - loss 0.00159392 - time (sec): 74.26 - samples/sec: 119.26 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 02:24:03,584 epoch 4 - iter 1230/1233 - loss 0.00143490 - time (sec): 82.29 - samples/sec: 119.57 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 02:24:03,773 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:24:03,774 EPOCH 4 done: loss 0.0014 - lr: 0.000011\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.48it/s]\n",
      "2024-11-10 02:24:05,157 DEV : loss 0.29005804657936096 - f1-score (micro avg)  0.9794\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 11.02it/s]\n",
      "2024-11-10 02:24:06,543 TEST : loss 0.29005804657936096 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:24:06,747 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:24:15,182 epoch 5 - iter 123/1233 - loss 0.00000242 - time (sec): 8.43 - samples/sec: 116.68 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:24:23,548 epoch 5 - iter 246/1233 - loss 0.00000199 - time (sec): 16.80 - samples/sec: 117.14 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 02:24:31,953 epoch 5 - iter 369/1233 - loss 0.00000192 - time (sec): 25.20 - samples/sec: 117.12 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 02:24:40,466 epoch 5 - iter 492/1233 - loss 0.00000395 - time (sec): 33.72 - samples/sec: 116.73 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 02:24:48,882 epoch 5 - iter 615/1233 - loss 0.00000342 - time (sec): 42.13 - samples/sec: 116.77 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 02:24:57,413 epoch 5 - iter 738/1233 - loss 0.00000310 - time (sec): 50.66 - samples/sec: 116.53 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 02:25:05,766 epoch 5 - iter 861/1233 - loss 0.00000281 - time (sec): 59.02 - samples/sec: 116.71 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 02:25:14,101 epoch 5 - iter 984/1233 - loss 0.00000262 - time (sec): 67.35 - samples/sec: 116.88 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 02:25:22,370 epoch 5 - iter 1107/1233 - loss 0.00000241 - time (sec): 75.62 - samples/sec: 117.11 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 02:25:30,700 epoch 5 - iter 1230/1233 - loss 0.00000228 - time (sec): 83.95 - samples/sec: 117.21 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 02:25:30,897 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:25:30,898 EPOCH 5 done: loss 0.0000 - lr: 0.000000\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 10.82it/s]\n",
      "2024-11-10 02:25:32,111 DEV : loss 0.2902233898639679 - f1-score (micro avg)  0.9794\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  9.32it/s]\n",
      "2024-11-10 02:25:33,714 TEST : loss 0.2902233898639679 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:25:35,755 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:25:35,756 Testing using last state of model ...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00, 11.20it/s]\n",
      "2024-11-10 02:25:36,929 \n",
      "Results:\n",
      "- F-score (micro) 0.9794\n",
      "- F-score (macro) 0.9403\n",
      "- Accuracy 0.9794\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ноутбук     1.0000    0.9870    0.9935       154\n",
      "      Сервер     0.9643    0.9310    0.9474        29\n",
      "         СХД     0.7857    1.0000    0.8800        11\n",
      "\n",
      "    accuracy                         0.9794       194\n",
      "   macro avg     0.9167    0.9727    0.9403       194\n",
      "weighted avg     0.9825    0.9794    0.9801       194\n",
      "\n",
      "2024-11-10 02:25:36,929 ----------------------------------------------------------------------------------------------------\n",
      "100%|███████████████████████████████████████████| 25/25 [00:01<00:00, 19.61it/s]\n",
      "2024/11/10 02:25:50 INFO mlflow.tracking._tracking_service.client: 🏃 View run polite-rat-423 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/78964a2b90a84ff5aa6af1ebed2d5b8b.\n",
      "2024/11/10 02:25:50 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n",
      "2024-11-10 02:25:56,275 Reading data from datav2\n",
      "2024-11-10 02:25:56,275 Train: datav2/train.csv\n",
      "2024-11-10 02:25:56,275 Dev: datav2/dev.csv\n",
      "2024-11-10 02:25:56,275 Test: datav2/test.csv\n",
      "2024-11-10 02:25:56,321 Computing label dictionary. Progress:\n",
      "0it [00:00, ?it/s]\n",
      "9860it [00:05, 1782.95it/s]\n",
      "2024-11-10 02:26:01,856 Dictionary created for label 'label' with 3 values: Ноутбук (seen 8130 times), Сервер (seen 1075 times), СХД (seen 655 times)\n",
      "2024-11-10 02:26:03,879 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,880 Model: \"TextClassifier(\n",
      "  (embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(250038, 384, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 384)\n",
      "        (token_type_embeddings): Embedding(2, 384)\n",
      "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSdpaSelfAttention(\n",
      "                (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=384, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-11-10 02:26:03,880 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Corpus: 9860 train + 194 dev + 194 test sentences\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Train:  9860 sentences\n",
      "2024-11-10 02:26:03,881         (train_with_dev=False, train_with_test=False)\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Training Params:\n",
      "2024-11-10 02:26:03,881  - learning_rate: \"5e-05\" \n",
      "2024-11-10 02:26:03,881  - mini_batch_size: \"8\"\n",
      "2024-11-10 02:26:03,881  - max_epochs: \"5\"\n",
      "2024-11-10 02:26:03,881  - shuffle: \"True\"\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Plugins:\n",
      "2024-11-10 02:26:03,881  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Final evaluation on model after last epoch (final-model.pt)\n",
      "2024-11-10 02:26:03,881  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Computation:\n",
      "2024-11-10 02:26:03,881  - compute on device: cuda:0\n",
      "2024-11-10 02:26:03,881  - embedding storage: none\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 Model training base path: \"modelsv2/datav2/intfloat_multilingual_e5_small\"\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:03,881 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:26:10,899 epoch 1 - iter 123/1233 - loss 0.65520835 - time (sec): 7.02 - samples/sec: 140.24 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:26:17,603 epoch 1 - iter 246/1233 - loss 0.37084727 - time (sec): 13.72 - samples/sec: 143.43 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:26:24,659 epoch 1 - iter 369/1233 - loss 0.25248048 - time (sec): 20.78 - samples/sec: 142.08 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:26:31,694 epoch 1 - iter 492/1233 - loss 0.19237101 - time (sec): 27.81 - samples/sec: 141.52 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:26:38,695 epoch 1 - iter 615/1233 - loss 0.15484049 - time (sec): 34.81 - samples/sec: 141.33 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-11-10 02:26:44,549 epoch 1 - iter 738/1233 - loss 0.12918834 - time (sec): 40.67 - samples/sec: 145.18 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-11-10 02:26:50,768 epoch 1 - iter 861/1233 - loss 0.11452456 - time (sec): 46.89 - samples/sec: 146.91 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-11-10 02:26:57,671 epoch 1 - iter 984/1233 - loss 0.10094000 - time (sec): 53.79 - samples/sec: 146.35 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-11-10 02:27:04,457 epoch 1 - iter 1107/1233 - loss 0.09050530 - time (sec): 60.57 - samples/sec: 146.20 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-11-10 02:27:11,246 epoch 1 - iter 1230/1233 - loss 0.08205343 - time (sec): 67.36 - samples/sec: 146.07 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-11-10 02:27:11,412 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:27:11,412 EPOCH 1 done: loss 0.0819 - lr: 0.000044\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 18.50it/s]\n",
      "2024-11-10 02:27:12,128 DEV : loss 0.09091053158044815 - f1-score (micro avg)  0.9845\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 15.04it/s]\n",
      "2024-11-10 02:27:13,197 TEST : loss 0.09091053158044815 - f1-score (micro avg)  0.9845\n",
      "2024-11-10 02:27:13,391 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:27:19,003 epoch 2 - iter 123/1233 - loss 0.00051474 - time (sec): 5.61 - samples/sec: 175.37 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-11-10 02:27:23,620 epoch 2 - iter 246/1233 - loss 0.00104492 - time (sec): 10.23 - samples/sec: 192.42 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-11-10 02:27:28,066 epoch 2 - iter 369/1233 - loss 0.00139149 - time (sec): 14.67 - samples/sec: 201.18 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-11-10 02:27:32,467 epoch 2 - iter 492/1233 - loss 0.00337955 - time (sec): 19.07 - samples/sec: 206.35 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-11-10 02:27:38,172 epoch 2 - iter 615/1233 - loss 0.00379502 - time (sec): 24.78 - samples/sec: 198.55 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-11-10 02:27:44,504 epoch 2 - iter 738/1233 - loss 0.00322894 - time (sec): 31.11 - samples/sec: 189.77 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-11-10 02:27:51,088 epoch 2 - iter 861/1233 - loss 0.00281891 - time (sec): 37.70 - samples/sec: 182.72 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-11-10 02:27:56,254 epoch 2 - iter 984/1233 - loss 0.00250717 - time (sec): 42.86 - samples/sec: 183.66 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-11-10 02:28:02,140 epoch 2 - iter 1107/1233 - loss 0.00226317 - time (sec): 48.75 - samples/sec: 181.67 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-11-10 02:28:07,558 epoch 2 - iter 1230/1233 - loss 0.00206693 - time (sec): 54.17 - samples/sec: 181.67 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-11-10 02:28:07,663 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:28:07,664 EPOCH 2 done: loss 0.0021 - lr: 0.000033\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 14.44it/s]\n",
      "2024-11-10 02:28:08,576 DEV : loss 0.07282549142837524 - f1-score (micro avg)  0.9897\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 17.71it/s]\n",
      "2024-11-10 02:28:09,533 TEST : loss 0.07282549142837524 - f1-score (micro avg)  0.9897\n",
      "2024-11-10 02:28:09,958 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:28:15,442 epoch 3 - iter 123/1233 - loss 0.00028646 - time (sec): 5.48 - samples/sec: 179.45 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-11-10 02:28:20,807 epoch 3 - iter 246/1233 - loss 0.00027269 - time (sec): 10.85 - samples/sec: 181.40 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-11-10 02:28:26,429 epoch 3 - iter 369/1233 - loss 0.00026517 - time (sec): 16.47 - samples/sec: 179.23 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-11-10 02:28:32,249 epoch 3 - iter 492/1233 - loss 0.00025870 - time (sec): 22.29 - samples/sec: 176.58 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-11-10 02:28:37,459 epoch 3 - iter 615/1233 - loss 0.00025202 - time (sec): 27.50 - samples/sec: 178.91 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-11-10 02:28:43,011 epoch 3 - iter 738/1233 - loss 0.00024741 - time (sec): 33.05 - samples/sec: 178.63 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-11-10 02:28:48,658 epoch 3 - iter 861/1233 - loss 0.00341898 - time (sec): 38.70 - samples/sec: 177.99 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-11-10 02:28:54,133 epoch 3 - iter 984/1233 - loss 0.00368798 - time (sec): 44.17 - samples/sec: 178.20 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-11-10 02:28:58,761 epoch 3 - iter 1107/1233 - loss 0.00403305 - time (sec): 48.80 - samples/sec: 181.47 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-11-10 02:29:03,656 epoch 3 - iter 1230/1233 - loss 0.00364976 - time (sec): 53.70 - samples/sec: 183.25 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-11-10 02:29:03,815 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:29:03,816 EPOCH 3 done: loss 0.0036 - lr: 0.000022\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 18.76it/s]\n",
      "2024-11-10 02:29:04,521 DEV : loss 0.13201873004436493 - f1-score (micro avg)  0.9742\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 17.93it/s]\n",
      "2024-11-10 02:29:05,672 TEST : loss 0.13201873004436493 - f1-score (micro avg)  0.9742\n",
      "2024-11-10 02:29:05,867 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:29:11,907 epoch 4 - iter 123/1233 - loss 0.00017645 - time (sec): 6.04 - samples/sec: 162.94 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-11-10 02:29:18,385 epoch 4 - iter 246/1233 - loss 0.00017545 - time (sec): 12.52 - samples/sec: 157.23 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-11-10 02:29:23,830 epoch 4 - iter 369/1233 - loss 0.00017378 - time (sec): 17.96 - samples/sec: 164.35 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-11-10 02:29:29,580 epoch 4 - iter 492/1233 - loss 0.00017301 - time (sec): 23.71 - samples/sec: 165.99 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-11-10 02:29:36,227 epoch 4 - iter 615/1233 - loss 0.00017140 - time (sec): 30.36 - samples/sec: 162.06 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-11-10 02:29:42,984 epoch 4 - iter 738/1233 - loss 0.00016777 - time (sec): 37.12 - samples/sec: 159.07 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-11-10 02:29:48,707 epoch 4 - iter 861/1233 - loss 0.00016414 - time (sec): 42.84 - samples/sec: 160.79 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-11-10 02:29:54,850 epoch 4 - iter 984/1233 - loss 0.00016081 - time (sec): 48.98 - samples/sec: 160.71 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-11-10 02:30:01,376 epoch 4 - iter 1107/1233 - loss 0.00015886 - time (sec): 55.51 - samples/sec: 159.54 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-11-10 02:30:07,836 epoch 4 - iter 1230/1233 - loss 0.00015677 - time (sec): 61.97 - samples/sec: 158.79 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-11-10 02:30:07,978 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:30:07,978 EPOCH 4 done: loss 0.0002 - lr: 0.000011\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 14.65it/s]\n",
      "2024-11-10 02:30:08,878 DEV : loss 0.13009817898273468 - f1-score (micro avg)  0.9794\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 19.06it/s]\n",
      "2024-11-10 02:30:09,767 TEST : loss 0.13009817898273468 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:30:09,974 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:30:16,415 epoch 5 - iter 123/1233 - loss 0.00013440 - time (sec): 6.44 - samples/sec: 152.80 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-11-10 02:30:23,245 epoch 5 - iter 246/1233 - loss 0.00013202 - time (sec): 13.27 - samples/sec: 148.30 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-11-10 02:30:29,479 epoch 5 - iter 369/1233 - loss 0.00013038 - time (sec): 19.50 - samples/sec: 151.35 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-11-10 02:30:34,868 epoch 5 - iter 492/1233 - loss 0.00012758 - time (sec): 24.89 - samples/sec: 158.11 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-11-10 02:30:40,433 epoch 5 - iter 615/1233 - loss 0.00012583 - time (sec): 30.46 - samples/sec: 161.53 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-11-10 02:30:46,361 epoch 5 - iter 738/1233 - loss 0.00012480 - time (sec): 36.39 - samples/sec: 162.26 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-11-10 02:30:51,667 epoch 5 - iter 861/1233 - loss 0.00012343 - time (sec): 41.69 - samples/sec: 165.21 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-11-10 02:30:56,835 epoch 5 - iter 984/1233 - loss 0.00012281 - time (sec): 46.86 - samples/sec: 167.99 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-11-10 02:31:02,604 epoch 5 - iter 1107/1233 - loss 0.00012158 - time (sec): 52.63 - samples/sec: 168.27 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-11-10 02:31:07,480 epoch 5 - iter 1230/1233 - loss 0.00012091 - time (sec): 57.51 - samples/sec: 171.11 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-11-10 02:31:07,608 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:31:07,608 EPOCH 5 done: loss 0.0001 - lr: 0.000000\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 18.36it/s]\n",
      "2024-11-10 02:31:08,328 DEV : loss 0.12319633364677429 - f1-score (micro avg)  0.9794\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 13.07it/s]\n",
      "2024-11-10 02:31:09,527 TEST : loss 0.12319633364677429 - f1-score (micro avg)  0.9794\n",
      "2024-11-10 02:31:10,664 ----------------------------------------------------------------------------------------------------\n",
      "2024-11-10 02:31:10,665 Testing using last state of model ...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:00<00:00, 18.98it/s]\n",
      "2024-11-10 02:31:11,362 \n",
      "Results:\n",
      "- F-score (micro) 0.9794\n",
      "- F-score (macro) 0.9471\n",
      "- Accuracy 0.9794\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ноутбук     1.0000    0.9870    0.9935       154\n",
      "      Сервер     0.9310    0.9310    0.9310        29\n",
      "         СХД     0.8462    1.0000    0.9167        11\n",
      "\n",
      "    accuracy                         0.9794       194\n",
      "   macro avg     0.9257    0.9727    0.9471       194\n",
      "weighted avg     0.9810    0.9794    0.9798       194\n",
      "\n",
      "2024-11-10 02:31:11,362 ----------------------------------------------------------------------------------------------------\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 27.21it/s]\n",
      "2024/11/10 02:31:18 INFO mlflow.tracking._tracking_service.client: 🏃 View run enchanting-grub-126 at: http://127.0.0.1:8082/#/experiments/654292010915275699/runs/332304d8b4bc422ba3bd573a2c400e9f.\n",
      "2024/11/10 02:31:18 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8082/#/experiments/654292010915275699.\n"
     ]
    }
   ],
   "source": [
    "model_names = [ 'deepvk/USER-bge-m3', 'deepvk/USER-base',\n",
    "               'intfloat/multilingual-e5-large-instruct', 'intfloat/multilingual-e5-large',\n",
    "               'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'intfloat/multilingual-e5-base', 'intfloat/multilingual-e5-small', \n",
    "               ]\n",
    "script_name = \"main.py\"\n",
    "for model in model_names:\n",
    "    data_folder='./datav2/'\n",
    "    experiment = 'Тип_оборудования_data_v2.0_expanded_data'\n",
    "    model_name = model\n",
    "    learning_rate = 5.0e-5\n",
    "    mini_batch_size = 8\n",
    "    max_epochs = 5\n",
    "    \n",
    "    command = f\"python {script_name} --experiment {experiment} --data_folder {data_folder} --model_name {model_name} --learning_rate {learning_rate} --mini_batch_size {mini_batch_size} --max_epochs {max_epochs}\"\n",
    "    !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519690ea-4e02-43c7-86a3-cd037ea75ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [ 'deepvk/USER-bge-m3', 'deepvk/USER-base',\n",
    "               'intfloat/multilingual-e5-large-instruct', 'intfloat/multilingual-e5-large',\n",
    "               'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'intfloat/multilingual-e5-base',\n",
    "               'sergeyzh/rubert-tiny-turbo', 'intfloat/multilingual-e5-small', \n",
    "               \"FacebookAI/xlm-roberta-large\"\n",
    "               ]\n",
    "script_name = \"main.py\"\n",
    "for model in model_names:\n",
    "    data_folder='./datav2/'\n",
    "    experiment = 'Тип_оборудования_data_v2.0_expanded_data'\n",
    "    model_name = model\n",
    "    learning_rate = 5.0e-5\n",
    "    mini_batch_size = 8\n",
    "    max_epochs = 5\n",
    "    \n",
    "    command = f\"python {script_name} --experiment {experiment} --data_folder {data_folder} --model_name {model_name} --learning_rate {learning_rate} --mini_batch_size {mini_batch_size} --max_epochs {max_epochs}\"\n",
    "    !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b9d3a-3b5d-4944-8326-047d04823f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14adf762-4774-4f9d-a12b-6d4af0318658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64924e49-783a-4b80-a2e7-a7f455e1ed96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31791f1-6669-4cca-9d12-348e31b035e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'deepvk/USER-bge-m3', 'deepvk/USER-base',\n",
    "               'intfloat/multilingual-e5-large-instruct', 'intfloat/multilingual-e5-large',\n",
    "               'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'intfloat/multilingual-e5-base',\n",
    "               'sergeyzh/rubert-tiny-turbo', 'intfloat/multilingual-e5-small', \n",
    "               \"FacebookAI/xlm-roberta-large\", \"yandex/RuLeanALBERT\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561850c-2499-475d-94ac-124785670917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294d771-4d3c-48e9-a81e-c5d81ec36a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b0d156-8439-4147-9170-f83a52ba5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ad260c9-e63a-49ce-93fa-9e20843baa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Не подается питание на ноутбук [SEP] Мой блок питания для ноутбука ACER перестал работать. Не включается ни при каких обстоятельствах.</th>\n",
       "      <th>Ноутбук</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Проблемы с зарядкой ноутбука [SEP] Блок питани...</td>\n",
       "      <td>Ноутбук</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Блок питания не включается [SEP] Вдруг переста...</td>\n",
       "      <td>Ноутбук</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ноутбук не реагирует на подключение питания [S...</td>\n",
       "      <td>Ноутбук</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Не удается зарядить ноутбук [SEP] Блок питания...</td>\n",
       "      <td>Ноутбук</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Неисправность блока питания [SEP] Мой блок пит...</td>\n",
       "      <td>Ноутбук</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>Ошибки после обновления системы [SEP] Здравств...</td>\n",
       "      <td>Сервер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>Проблемы с совместимостью после обновления [SE...</td>\n",
       "      <td>Сервер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>Запрос на обновление сетевых драйверов [SEP] З...</td>\n",
       "      <td>Сервер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>Обновление программного обеспечения сервера [S...</td>\n",
       "      <td>Сервер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>Ошибки после обновления BMC [SEP] Здравствуйте...</td>\n",
       "      <td>Сервер</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Не подается питание на ноутбук [SEP] Мой блок питания для ноутбука ACER перестал работать. Не включается ни при каких обстоятельствах.  \\\n",
       "0     Проблемы с зарядкой ноутбука [SEP] Блок питани...                                                                                       \n",
       "1     Блок питания не включается [SEP] Вдруг переста...                                                                                       \n",
       "2     Ноутбук не реагирует на подключение питания [S...                                                                                       \n",
       "3     Не удается зарядить ноутбук [SEP] Блок питания...                                                                                       \n",
       "4     Неисправность блока питания [SEP] Мой блок пит...                                                                                       \n",
       "...                                                 ...                                                                                       \n",
       "1634  Ошибки после обновления системы [SEP] Здравств...                                                                                       \n",
       "1635  Проблемы с совместимостью после обновления [SE...                                                                                       \n",
       "1636  Запрос на обновление сетевых драйверов [SEP] З...                                                                                       \n",
       "1637  Обновление программного обеспечения сервера [S...                                                                                       \n",
       "1638  Ошибки после обновления BMC [SEP] Здравствуйте...                                                                                       \n",
       "\n",
       "      Ноутбук  \n",
       "0     Ноутбук  \n",
       "1     Ноутбук  \n",
       "2     Ноутбук  \n",
       "3     Ноутбук  \n",
       "4     Ноутбук  \n",
       "...       ...  \n",
       "1634   Сервер  \n",
       "1635   Сервер  \n",
       "1636   Сервер  \n",
       "1637   Сервер  \n",
       "1638   Сервер  \n",
       "\n",
       "[1639 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/train.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47beffac-1bda-47cd-8446-5e3975d48d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
